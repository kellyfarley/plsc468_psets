---
title: "PLSC 468 Pset 3"
author: "Kelly Farley, Numi Katz, and Chelsea Wang"
date: "4/8/2022"
output:
  html_document:
    toc: yes
    toc_float: yes
    theme: united
  pdf_document:
    toc: yes
---

```{r setup, include=FALSE}
rm(list = ls()) # clear global environ

knitr::opts_chunk$set(echo = TRUE, cache = TRUE, warning = FALSE, message = FALSE)

# set working directory (change for each user)
wd <- "/Users/kellyfarley/Desktop/machine_learning/plsc468_psets"
#wd <- "/Users/numikatz/Documents/Senior_Year/Spring_22/PLSC_468/PLSC_468/plsc468_psets"
knitr::opts_knit$set(root.dir = wd)

# load libraries
library(tidyverse)
library(stringr)
library(tm)
library(RWeka)
library(lda)
library(topicmodels) 
library(lda)
library(stm)
```
Setting the seed for future randomization:

```{r}
set.seed(1005)
```

Loading papers from .rda file:

```{r}
load(file = "pset3/adData.Rdata")
```

Goal: to estimate a series of unsupervised topic models using 3255 ads aired in 2008

# Part 1

**Goal: Choose an appropriate value to set for the number of topics *K* that will be estimated for each model**

*Our choice of K:*

*Description of method:*

*Defense of method:*

*Preprocessing of ad strings into correct format for lda() and stm():*

```{r}
#collect some covars
year=str_sub(rownames(tdoc),1,4)
pty=pty
state=str_sub(rownames(tdoc),6,7)
platforms=as.data.frame(cbind(pty,year,state),stringsAsFactors=F)
platforms[,1]=as.numeric(platforms[,1])
platforms[,2]=as.factor(platforms[,2])
platforms[,3]=as.factor(platforms[,3])

# reproduce strings from word counts for use in lexicalize
strs=array(NA,nrow(tdoc))
for(i in 1:nrow(tdoc)){
	strs[i]=paste(names(which((tdoc[i,])>0)),collapse=' ')
}

platforms$texts=strs
```

```{r}
# 5. tuning lda to improve selection K
library(ldatuning)

result[[5]] <- FindTopicsNumber(
  xdm,
  topics = seq(from = 2, to = 15, by = 1),
  metrics = c("Griffiths2004", "CaoJuan2009", "Arun2010", "Deveaud2014"),
  method = "Gibbs",
  control = list(seed = 77),
  mc.cores = 2L,
  verbose = TRUE
)
```

# Part 2

**Goal: Setting k = K, estimate the following topic models. For each model, produce a list of the top 10 most frequent works across each of the k topics**

## 2a: Unsupervised LDA model using lda::lda.collapsed.gibs.sampler(.., k) (Numi)

```{r}
# 1. baseline LDA
set.seed(1005)

# pre-processing step prior to lexicalizing in the text
#texts20=texts[iq] # retained from above, indexing those with at least 10 words

# lda package has a specific function used to count words: lexicalize
#  - lexicalize counts words in string array 'texts', and stores them in compact fashion
#  - compactness is achieved by ignored word counts when these are 0 (zero)
#  - side not, lexicalize also ignores 'counts' and just sets mentions to be 0,1

docs=lexicalize(strs)
# you can extract the word list in the 2nd part of the docs list object
vocab=docs[[2]]
result=list()
# this is the workhorse function
k=10 # pre-specify # of topics
result[[1]]=lda.collapsed.gibbs.sampler(docs[[1]], 		## lexicalized word counts
	k,  			## k num of clusters
	vocab,		## vocab list in docs[[2]] #
	100,  ## Num iterations
	alpha = 0.1, # Note the alpha prior is pre-set; ideally would tune this using some validation
	eta = 0.1,   # Note the eta prior is pre-set; ideally would tune this using some validation
	compute.log.likelihood=TRUE
)

###################################################
lda_results <- top.topic.words(result[[1]]$topics,10)

```

## 2b: Supervised LDA model to predict *party* using lda::slda.em(..., party, k) (Numi)

```{r}
# 2. sLDA = inferring topics by predicting an outcome/annotation
# pre-set some parameters
set.seed(1005)
k = 10
# starting values for prediction
params = sample(c(-1, 1), k, replace=TRUE)
alpha = 1.0
eta = 0.1

# annotation to predict
y=pty

result[[2]]=slda.em(documents=docs[[1]],
		K=k,
		vocab=vocab,
		num.e.iterations=10,
		num.m.iterations=4,
		alpha=alpha, eta=eta,
		annotations=y,
		params,
		variance=0.25,
		lambda=1.0,
		logistic=FALSE, # gaussian outcomes when FALSe
		method="sLDA"
)

###################################################
top.topic.words(result[[2]]$topics,10)

# 2. sLDA = inferring topics by predicting an outcome/annotation
# pre-set some parameters
set.seed(1005)
#preset topics
k = 10
# starting values for prediction--> here they are -1 and 1 as long as they vary
params = sample(c(-1, 1), k, replace=TRUE)
#set alpha--> by default set at 1
alpha = 1.0
#t a
eta = 0.1

# annotation to predict --> use party to constrian dist of topics 
y=pty

#exp maximization
result[[2]]=slda.em(documents=docs[[1]],
		K=k,
		vocab=vocab,
		num.e.iterations=10,
		#inc iterations --> more convergence
		num.m.iterations=4,
		alpha=alpha, 
		eta=eta,
		annotations=y,
		params,
		#reg coeffs prior parameters
		variance=0.25,
		lambda=1.0,
		logistic=FALSE, # gaussian outcomes when FALSe
		method="sLDA"
)

slda_party_results <- top.topic.words(result[[2]]$topics,10)
```

## 2c: Supervised LDA model to predict *tone* using lda::slda.em(..., tone, k) (Numi)
```{r}
# 2. sLDA = inferring topics by predicting an outcome/annotation
# pre-set some parameters
set.seed(1005)
k = 10
# starting values for prediction
params = sample(c(-1, 1), k, replace=TRUE)
alpha = 1.0
eta = 0.1

# annotation to predict
y=pty

result[[2]]=slda.em(documents=docs[[1]],
		K=k,
		vocab=vocab,
		num.e.iterations=10,
		num.m.iterations=4,
		alpha=alpha, eta=eta,
		annotations=y,
		params,
		variance=0.25,
		lambda=1.0,
		logistic=FALSE, # gaussian outcomes when FALSe
		method="sLDA"
)

###################################################
top.topic.words(result[[2]]$topics,10)

k = k
# starting values for prediction--> here they are -1 and 1 as long as they vary
params = sample(c(-1, 1), k, replace=TRUE)
#set alpha--> by default set at 1
alpha = 1.0
#t a
eta = 0.1

# annotation to predict --> use party to constrian dist of topics 
y=tone

#exp maximization
result[[2]]=slda.em(documents=docs[[1]],
		K=k,
		vocab=vocab,
		num.e.iterations=10,
		#inc iterations --> more convergence
		num.m.iterations=4,
		alpha=alpha, 
		eta=eta,
		annotations=y,
		params,
		#reg coeffs prior parameters
		variance=0.25,
		lambda=1.0,
		logistic=FALSE, # gaussian outcomes when FALSe
		method="sLDA"
)

slda_tone_results <- top.topic.words(result[[2]]$topics,10)
```

## 2d: Structural topic model using stm::stm(..., prevalence = ~ party + tone, k) (Kelly)

Good reference: https://sicss.io/2019/materials/day3-text-analysis/topic-modeling/rmarkdown/Topic_Modeling.html

We use the function textProcessor() to build our corpus. This function converts text to lowercase, removes punctuation, stopwords, and numbers, and stems words.

```{r}
load("pset3/adData.Rdata") # laod data

processed <- textProcessor(ads$texts, metadata = ads) # clean data

# stm pacakge requires storing docs, meta data, and vocab
out <- prepDocuments(processed$documents, processed$vocab, processed$meta) # eliminates very common and very rare terms
docs <- out$documents
vocab <- out$vocab
meta <-out$meta

# 3. stm set some structure and parsing code
# textProcessor() => produces the data structure that is modeled in

temp = textProcessor(documents=platforms$texts,metadata=platforms[,1:3])
outs = prepDocuments(temp$documents, temp$vocab, temp$meta)

k=10
set.seed(1005)
result[[3]] = stm(documents=outs$documents,vocab=outs$vocab,K=k,
	prevalence=~pty+year+state,data=outs$meta
)


###################################################
# outputs

names(result[[3]])

# (less than parsimonious) interface for collecting top 20 words =>
stm_results <- t(labelTopics(model=result[[3]], topics = NULL, n = 10, frexweight = 0.5)[1]$prob)

# 4. CTM in topicmodels
# unlike above, operates directly on a 'DocumentTermMatrix' object produced in tm

docs = Corpus(VectorSource(platforms$texts))
tdm = DocumentTermMatrix(docs)
xdm=tdm[,which(colSums(as.matrix(tdm))>200)]
xdm=xdm[which(rowSums(as.matrix(xdm))>0),]

result[[4]]=CTM(x=xdm, k=k)
slotNames(result[[4]])
terms(result[[4]], 20)

library(tidytext)
# tibbles using tidy
#https://books.psychstat.org/textmining/topic-models.html
r.topics = tidy(result[[4]], matrix = "beta")
```

## 2e: Structural topic model using stm::stm(..., prevalence = ~ party + tone + office + policy + as.factor(state), k) (Kelly)

## Reflection
**Are these roughly the same topics, or are there major differences in the topics being estimated?**
We report the top ten words for each model specification in the results matrix. 
```{r}
result_matrix <- rbind(lda_results, slda_party_results, slda_tone_results, stm_results)
```

