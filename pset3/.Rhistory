library(rjson)
rm(list = ls()) # clear global environ
knitr::opts_chunk$set(echo = TRUE, cache = TRUE, warning = FALSE, message = FALSE)
# set working directory (change for each user)
wd <- "/Users/kellyfarley/Desktop/machine_learning/plsc468_psets"
#wd <- "/Users/numikatz/Documents/Senior_Year/Spring_22/PLSC_468/PLSC_468/plsc468_psets"
knitr::opts_knit$set(root.dir = wd)
# load libraries
library(e1071)
library(stringr)
library(rjson)
library(tm)
library(tidyverse)
raw <- fromJSON(file="final_project/oyez_pretty.json")
str(raw)
View(raw)
raw[[1]]
library("reticulate")
install.packages("reticulate")
py_install("pandas")
pickle_data <- read_pickle_file("/Users/kellyfarley/Desktop/task1_data.pkl")
library(reticulate)
pd <- import("pandas")
pickle_data <- pd$read_pickle("/Users/kellyfarley/Desktop/task1_data.pkl")
pd <- import("pandas")
py_load_object("/Users/kellyfarley/Desktop/task1_data.pkl", pickle = "pickle")
library("pickle")
install.packages("pickel")
install.packages("pickle")
library(reticulate)
py_load_object("/Users/kellyfarley/Desktop/task1_data.pkl", pickle = "pickle")
rm(list = ls()) # clear global environ
library(reticulate)
py_install("pandas")
py_load_object("/Users/kellyfarley/Desktop/task1_data.pkl", pickle = "pickle")
raw <- py_load_object("/Users/kellyfarley/Desktop/task1_data.pkl", pickle = "pickle")
View(Raw)
View(raw)
task1 <- py_load_object("/Users/kellyfarley/Desktop/task1_data.pkl", pickle = "pickle")
class0 <- py_load_object("/Users/kellyfarley/Desktop/class0.pkl", pickle = "pickle")
class1 <- py_load_object("/Users/kellyfarley/Desktop/class1.pkl", pickle = "pickle")
clean <- read_csv(url("https://raw.githubusercontent.com/smitp415/CSCI_544_Final_Project/main/clean_data.csv"))
View(task1)
View(class0)
View(class1)
View(clean)
rm(list = ls()) # clear global environ
knitr::opts_chunk$set(echo = TRUE, cache = TRUE, warning = FALSE, message = FALSE)
# set working directory (change for each user)
wd <- "/Users/kellyfarley/Desktop/machine_learning/plsc468_psets"
#wd <- "/Users/numikatz/Documents/Senior_Year/Spring_22/PLSC_468/PLSC_468/plsc468_psets"
knitr::opts_knit$set(root.dir = wd)
# load libraries
library(reticulate)
py_install("pandas")
# data source: https://github.com/smitp415/CSCI_544_Final_Project
# has multiple data sets...
task1 <- py_load_object("/Users/kellyfarley/Desktop/task1_data.pkl", pickle = "pickle")
class0 <- py_load_object("/Users/kellyfarley/Desktop/class0.pkl", pickle = "pickle")
class1 <- py_load_object("/Users/kellyfarley/Desktop/class1.pkl", pickle = "pickle")
clean <- read_csv(url("https://raw.githubusercontent.com/smitp415/CSCI_544_Final_Project/main/clean_data.csv")) # i think this is the best one to be using because it has the most information
raw <- clean
clean
rm(list = ls()) # clear global environ
knitr::opts_chunk$set(echo = TRUE, cache = TRUE, warning = FALSE, message = FALSE)
# set working directory (change for each user)
wd <- "/Users/kellyfarley/Desktop/machine_learning/plsc468_psets"
#wd <- "/Users/numikatz/Documents/Senior_Year/Spring_22/PLSC_468/PLSC_468/plsc468_psets"
knitr::opts_knit$set(root.dir = wd)
# load libraries
library(e1071)
library(stringr)
library(tm)
library(tidyverse)
load(file = "pset2/federalists.Rdata")
View(papers)
# data source: https://github.com/smitp415/CSCI_544_Final_Project
# has multiple data sets...
task1 <- py_load_object("/Users/kellyfarley/Desktop/task1_data.pkl", pickle = "pickle")
class0 <- py_load_object("/Users/kellyfarley/Desktop/class0.pkl", pickle = "pickle")
class1 <- py_load_object("/Users/kellyfarley/Desktop/class1.pkl", pickle = "pickle")
clean <- read_csv(url("https://raw.githubusercontent.com/smitp415/CSCI_544_Final_Project/main/clean_data.csv")) # i think this is the best one to be using because it has the most information
dat <- clean
names(clean)
texts=VCorpus(VectorSource(dat$facts))
stops <- stopwords(kind = "en")
# note apostrophes are not removed in stops, but are in our texts
stops <- c(gsub(stops, pattern="[']", replace=''))
# make corpus
texts=VCorpus(VectorSource(dat$facts))
# make dtm
dtm = as.matrix(DocumentTermMatrix(texts))
# remove non stop words
non.stops=array(TRUE,ncol(dtm))
stops=sort(stops)
col.names=colnames(dtm)
for(j in 1:length(stops)){
ik=which(stops[j]==col.names)
if(length(ik)>0){
non.stops[ik]=F
}
}
non.dtm  = dtm[,non.stops] # non-stop words
stop.dtm = dtm[,!non.stops] # stop words
non.dtm
dtm
# using stop words from stopword() package
stops <- stopwords(kind = "en")
# note apostrophes are not removed in stops, but are in our texts
stops <- c(gsub(stops, pattern="[']", replace=''))
# make corpus
texts=VCorpus(VectorSource(dat$facts))
# make dtm
dtm = as.matrix(DocumentTermMatrix(texts))
# remove non stop words
non.stops=array(TRUE,ncol(dtm))
stops=sort(stops)
col.names=colnames(dtm)
for(j in 1:length(stops)){
ik=which(stops[j]==col.names)
if(length(ik)>0){
non.stops[ik]=F
}
}
non.dtm  = dtm[,non.stops] # non-stop words
stop.dtm = dtm[,!non.stops] # stop words
View(dtm)
