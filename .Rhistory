# annotation to predict
y=ads$party
result_2b=slda.em(documents=docs[[1]],
K=k,
vocab=vocab,
num.e.iterations=10,
num.m.iterations=4,
alpha=alpha, eta=eta,
annotations=y,
params,
variance=0.25,
lambda=1.0,
logistic=FALSE,
method="sLDA"
)
###################################################
slda_party_results <- top.topic.words(result_2b$topics,10)
# annotation to predict
y=ads$tone
result_2c=slda.em(documents=docs[[1]],
K=k,
vocab=vocab,
num.e.iterations=10,
num.m.iterations=4,
alpha=alpha, eta=eta,
annotations=y,
params,
variance=0.25,
lambda=1.0,
logistic=FALSE,
method="sLDA"
)
###################################################
slda_tone_results <- top.topic.words(result_2c$topics,10)
plot(results_2a)
plot(result_2a)
variable.names(result_2a)
#running the model!
result_2a=lda.collapsed.gibbs.sampler(docs[[1]],
k,
vocab,
100,
alpha = alpha,
eta = eta,
compute.log.likelihood=TRUE
)
#running the model!
result_2a=lda.collapsed.gibbs.sampler(docs[[1]],
k,
vocab,
100,
alpha = alpha,
eta = eta,
compute.log.likelihood=TRUE
)
###################################################
lda_results <- top.topic.words(result_2a$topics,10)
lda_results
variable.names(result_2a)
names(result_2a)
plot(result_2a$log.likelihoods)
plot(result_2a$document_sums)
plot(result_2a$topic_sums)
plot(result_2a$topic)
plot(result_2a$topic)
plot(result_2a)
result_matrix <- rbind(lda_results, slda_party_results, slda_tone_results, stm_results_2d, stm_results_2e)
lda_results
```{r setup, include=FALSE}
rm(list = ls()) # clear global environ
wd <- "/Users/numikatz/Documents/Senior_Year/Spring_22/PLSC_468/PLSC_468/plsc468_psets"
knitr::opts_knit$set(root.dir = wd)
library(tidyverse)
library(stringr)
library(tm)
library(lda)
library(topicmodels)
library(stm)
library(ldatuning)
library(SnowballC)
set.seed(1005)
load(file = "adData.Rdata")
#taking text data from ads
txts=ads$texts
#stemming words
txts=stemDocument(txts)
#changing to lowercase
txts=tolower(txts)
#removing stopwords
txts=removeWords(txts,stopwords("english"))
txts=stripWhitespace(txts)
#lexicalize strings for lda()
docs=lexicalize(txts)
ads$txts=txts
temp_stm = textProcessor(documents=ads$txts,metadata=ads[,2:7])
outs_stm = prepDocuments(temp_stm$documents, temp_stm$vocab, temp_stm$meta)
# determining best value of K
findingk <- searchK(outs_stm$documents, outs_stm$vocab, K = c(5, 10, 15, 20, 50),
prevalence =~ party + tone, data = outs_stm$meta, verbose=FALSE)
k = 11 # thoughts?
# code from chelsea (done in the same way as class)
# creating a tdm of documents
docs = Corpus(VectorSource(outs_stm$documents))
tdm = DocumentTermMatrix(docs)
# calculating lda tuning metrics - big picture overview
metrics <- FindTopicsNumber(
tdm,
topics = seq(from = 2, to = 100, by = 20),
metrics = c("Griffiths2004", "CaoJuan2009", "Arun2010", "Deveaud2014"),
method = "Gibbs",
control = list(seed = 77),
mc.cores = 2L,
verbose = TRUE
)
FindTopicsNumber_plot(metrics)
# calculating lda tuning metrics - 5-30
metrics_final <- FindTopicsNumber(
tdm,
topics = seq(from = 5, to = 30, by = 1),
metrics = c("Griffiths2004", "CaoJuan2009", "Arun2010", "Deveaud2014"),
method = "Gibbs",
control = list(seed = 77),
mc.cores = 2L,
verbose = TRUE
)
#processing text for lda analysis
vocab = docs[[2]]
result=list()
#preset parameters for lda() models
alpha = 1.0
eta = 0.1
params = sample(c(-1, 1), k, replace=TRUE)
#running the model!
result_2a=lda.collapsed.gibbs.sampler(docs[[1]],
k,
vocab,
100,
alpha = alpha,
eta = eta,
compute.log.likelihood=TRUE
)
vocab = docs[[2]]
result=list()
#preset parameters for lda() models
alpha = 1.0
eta = 0.1
params = sample(c(-1, 1), k, replace=TRUE)
#running the model!
result_2a=lda.collapsed.gibbs.sampler(docs[[1]],
k,
vocab,
100,
alpha = alpha,
eta = eta,
compute.log.likelihood=TRUE
)
k = 11
#processing text for lda analysis
vocab = docs[[2]]
result=list()
#preset parameters for lda() models
alpha = 1.0
eta = 0.1
params = sample(c(-1, 1), k, replace=TRUE)
#running the model!
result_2a=lda.collapsed.gibbs.sampler(docs[[1]],
k,
vocab,
100,
alpha = alpha,
eta = eta,
compute.log.likelihood=TRUE
)
vocab = docs[[2]]
result=list()
#preset parameters for lda() models
alpha = 1.0
eta = 0.1
params = sample(c(-1, 1), k, replace=TRUE)
#running the model!
result_2a=lda.collapsed.gibbs.sampler(docs[[1]],
k,
vocab,
100,
alpha = alpha,
eta = eta,
compute.log.likelihood=TRUE
)
###################################################
lda_results <- top.topic.words(result_2a$topics,10)
#taking text data from ads
txts=ads$texts
#stemming words
txts=stemDocument(txts)
#changing to lowercase
txts=tolower(txts)
#removing stopwords
txts=removeWords(txts,stopwords("english"))
txts=stripWhitespace(txts)
#lexicalize strings for lda()
docs=lexicalize(txts)
#processing text for lda analysis
vocab = docs[[2]]
result=list()
#preset parameters for lda() models
alpha = 1.0
eta = 0.1
params = sample(c(-1, 1), k, replace=TRUE)
#running the model!
result_2a=lda.collapsed.gibbs.sampler(docs[[1]],
k,
vocab,
100,
alpha = alpha,
eta = eta,
compute.log.likelihood=TRUE
)
###################################################
lda_results <- top.topic.words(result_2a$topics,10)
ads$txts=txts
temp_stm = textProcessor(documents=ads$txts,metadata=ads[,2:7])
outs_stm = prepDocuments(temp_stm$documents, temp_stm$vocab, temp_stm$meta)
#processing text for lda analysis
vocab = docs[[2]]
result=list()
#preset parameters for lda() models
alpha = 1.0
eta = 0.1
params = sample(c(-1, 1), k, replace=TRUE)
#running the model!
result_2a=lda.collapsed.gibbs.sampler(docs[[1]],
k,
vocab,
100,
alpha = alpha,
eta = eta,
compute.log.likelihood=TRUE
)
###################################################
lda_results <- top.topic.words(result_2a$topics,10)
# annotation to predict
y=ads$party
result_2b=slda.em(documents=docs[[1]],
K=k,
vocab=vocab,
num.e.iterations=10,
num.m.iterations=4,
alpha=alpha, eta=eta,
annotations=y,
params,
variance=0.25,
lambda=1.0,
logistic=FALSE,
method="sLDA"
)
###################################################
slda_party_results <- top.topic.words(result_2b$topics,10)
# annotation to predict
y=ads$tone
result_2c=slda.em(documents=docs[[1]],
K=k,
vocab=vocab,
num.e.iterations=10,
num.m.iterations=4,
alpha=alpha, eta=eta,
annotations=y,
params,
variance=0.25,
lambda=1.0,
logistic=FALSE,
method="sLDA"
)
###################################################
slda_tone_results <- top.topic.words(result_2c$topics,10)
result_2d = stm(documents=outs_stm$documents,vocab=outs_stm$vocab,K=k,
prevalence=~party+tone,data=outs_stm$meta)
# view 3 top words associated with each topic
plot(result_2d)
# (less than parsimonious) interface for collecting top 10 words =>
stm_results_2d <- t(labelTopics(model=result_2d, topics = NULL, n = 10, frexweight = 0.5)[1]$prob)
result_2e = stm(documents=outs_stm$documents,vocab=outs_stm$vocab,K=k,
prevalence=~party+tone+office+policy+as.factor(state),data=outs_stm$meta)
# (less than parsimonious) interface for collecting top 10 words =>
stm_results_2d <- t(labelTopics(model=result_2d, topics = NULL, n = 10, frexweight = 0.5)[1]$prob)
# (less than parsimonious) interface for collecting top 10 words =>
stm_results_2e <- t(labelTopics(model=result_2e, topics = NULL, n = 10, frexweight = 0.5)[1]$prob)
result_matrix <- rbind(lda_results, slda_party_results, slda_tone_results, stm_results_2d, stm_results_2e)
tibble(result_matrix)
result_matrix
bob <- result_matrix %>%
group_by(topic)
tibble(result_matrix)
result_matrix
result_matrix
as.dataframe(result_matrix) <- rbind(lda_results, slda_party_results, slda_tone_results, stm_results_2d, stm_results_2e)
as.data.frame(result_matrix) <- rbind(lda_results, slda_party_results, slda_tone_results, stm_results_2d, stm_results_2e)
result_matrix <- rbind(lda_results, slda_party_results, slda_tone_results, stm_results_2d, stm_results_2e)
result_matrix
colnames(resultsMat) <- c("Topic 1", "Topic 2", "Topic 3", "Topic 4", "Topic 5", "Topic 6", "Topic 7",
"Topic 8", "Topic 9", "Topic 10", "Topic 11")
colnames(result_matrix) <- c("Topic 1", "Topic 2", "Topic 3", "Topic 4", "Topic 5", "Topic 6", "Topic 7",
"Topic 8", "Topic 9", "Topic 10", "Topic 11")
result_matrix <- as.data.frame(result_matrix)
result_matrix
result_matrix <- cbind(lda_results, slda_party_results, slda_tone_results, stm_results_2d, stm_results_2e)
rownames(result_matrix) <- c("Topic 1", "Topic 2", "Topic 3", "Topic 4", "Topic 5", "Topic 6", "Topic 7",
"Topic 8", "Topic 9", "Topic 10", "Topic 11")
result_matrix <- cbind(lda_results, slda_party_results, slda_tone_results, stm_results_2d, stm_results_2e)
result_matrix
rownames(lda_results) <- c("Topic 1", "Topic 2", "Topic 3", "Topic 4", "Topic 5", "Topic 6", "Topic 7",
"Topic 8", "Topic 9", "Topic 10", "Topic 11")
lda_results
colnames(lda_results) <- c("Topic 1", "Topic 2", "Topic 3", "Topic 4", "Topic 5", "Topic 6", "Topic 7",
"Topic 8", "Topic 9", "Topic 10", "Topic 11")
tibble(lda_results)
lda_results
colnames(lda_results) <- c("Topic 1", "Topic 2", "Topic 3", "Topic 4", "Topic 5", "Topic 6", "Topic 7",
"Topic 8", "Topic 9", "Topic 10", "Topic 11")
tibble(lda_results)
colnames(slda_party_results) <- c("Topic 1", "Topic 2", "Topic 3", "Topic 4", "Topic 5", "Topic 6", "Topic 7",
"Topic 8", "Topic 9", "Topic 10", "Topic 11")
tibble(slda_party_results)
colnames(slda_tone_results) <- c("Topic 1", "Topic 2", "Topic 3", "Topic 4", "Topic 5", "Topic 6", "Topic 7",
"Topic 8", "Topic 9", "Topic 10", "Topic 11")
tibble(slda_tone_results)
colnames(stm_results_2d) <- c("Topic 1", "Topic 2", "Topic 3", "Topic 4", "Topic 5", "Topic 6", "Topic 7",
"Topic 8", "Topic 9", "Topic 10", "Topic 11")
tibble(stm_results_2d)
colnames(stm_results_2e) <- c("Topic 1", "Topic 2", "Topic 3", "Topic 4", "Topic 5", "Topic 6", "Topic 7",
"Topic 8", "Topic 9", "Topic 10", "Topic 11")
tibble(stm_results_2e)
stm_results_2e
colnames(stm_results_2e) <- c("Topic 1", "Topic 2", "Topic 3", "Topic 4", "Topic 5", "Topic 6", "Topic 7",
"Topic 8", "Topic 9", "Topic 10", "Topic 11")
tibble(stm_results_2e)
tibble(stm_results_2e)
stm_results_2e
rownames(stm_results_2e) <- ("#1", "#2", "#3", "#4", "#5", "#6" , "#7", "#8", "9", "#10" ,"#11")
rownames(stm_results_2e) <- c("#1", "#2", "#3", "#4", "#5", "#6" , "#7", "#8", "9", "#10" ,"#11")
colnames(stm_results_2e) <- c("Topic 1", "Topic 2", "Topic 3", "Topic 4", "Topic 5", "Topic 6", "Topic 7",
"Topic 8", "Topic 9", "Topic 10", "Topic 11")
rownames(stm_results_2e) <- c("#1", "#2", "#3", "#4", "#5", "#6" , "#7", "#8", "9", "#10" ,"#11")
rownames(stm_results_2e) <- c("#1", "#2", "#3", "#4", "#5", "#6" , "#7", "#8", "9", "#10")
tibble(stm_results_2e)
stm_results_2e
colnames(lda_results) <- c("Topic 1", "Topic 2", "Topic 3", "Topic 4", "Topic 5", "Topic 6", "Topic 7",
"Topic 8", "Topic 9", "Topic 10", "Topic 11")
rownames(lda_results) <- c("#1", "#2", "#3", "#4", "#5", "#6" , "#7", "#8", "9", "#10")
tibble(lda_results)
colnames(slda_party_results) <- c("Topic 1", "Topic 2", "Topic 3", "Topic 4", "Topic 5", "Topic 6", "Topic 7",
"Topic 8", "Topic 9", "Topic 10", "Topic 11")
rownames(slda_party_results) <- c("#1", "#2", "#3", "#4", "#5", "#6" , "#7", "#8", "9", "#10")
tibble(slda_party_results)
colnames(slda_tone_results) <- c("Topic 1", "Topic 2", "Topic 3", "Topic 4", "Topic 5", "Topic 6", "Topic 7",
"Topic 8", "Topic 9", "Topic 10", "Topic 11")
rownames(slda_tone_results) <- c("#1", "#2", "#3", "#4", "#5", "#6" , "#7", "#8", "9", "#10")
tibble(slda_tone_results)
colnames(stm_results_2d) <- c("Topic 1", "Topic 2", "Topic 3", "Topic 4", "Topic 5", "Topic 6", "Topic 7",
"Topic 8", "Topic 9", "Topic 10", "Topic 11")
rownames(stm_results_2d) <- c("#1", "#2", "#3", "#4", "#5", "#6" , "#7", "#8", "9", "#10")
tibble(stm_results_2d)
colnames(stm_results_2e) <- c("Topic 1", "Topic 2", "Topic 3", "Topic 4", "Topic 5", "Topic 6", "Topic 7",
"Topic 8", "Topic 9", "Topic 10", "Topic 11")
rownames(stm_results_2e) <- c("#1", "#2", "#3", "#4", "#5", "#6" , "#7", "#8", "9", "#10")
tibble(stm_results_2e)
variable.names(stm_results_2e)
ggplot(data = stm_results_2e, aes(x = Topic 1)) +
ggplot(data = stm_results_2e, aes(x = Topic)) +
geom_hist()
ggplot(data = stm_results_2e, aes(x = "Topic")) +
geom_hist()
stm_results_2e
slda_tone_results <- top.topic.words(result_2c$topics,10)
colnames(slda_tone_results) <- c("Topic 1", "Topic 2", "Topic 3", "Topic 4", "Topic 5", "Topic 6", "Topic 7",
"Topic 8", "Topic 9", "Topic 10", "Topic 11")
rownames(slda_tone_results) <- c("#1", "#2", "#3", "#4", "#5", "#6" , "#7", "#8", "9", "#10")
tibble(slda_tone_results)
lda_results
slda_party_results
slda_tone_results
stm_results_2d
stm_results_2e
slda_tone_results
rm(list = ls()) # clear global environ
knitr::opts_chunk$set(echo = TRUE, cache = TRUE, warning = FALSE, message = FALSE)
# set working directory (change for each user)
wd <- "/Users/kellyfarley/Desktop/machine_learning/plsc468_psets"
#wd <- "/Users/numikatz/Documents/Senior_Year/Spring_22/PLSC_468/PLSC_468/plsc468_psets"
knitr::opts_knit$set(root.dir = wd)
# load libraries
library(tidyverse)
library(stringr)
library(tm)
library(RWeka)
"/Users/numikatz/Documents/Senior_Year/Spring_22/PLSC_468/PLSC_468/plsc468_psets"
library(tidyverse)
library(stringr)
library(tm)
library(lda)
library(topicmodels)
library(stm)
library(ldatuning)
library(SnowballC)
set.seed(1005)
load(file = "adData.Rdata")
load(file = "pset3/adData.Rdata")
#taking text data from ads
txts=ads$texts
#stemming words
txts=stemDocument(txts)
#changing to lowercase
txts=tolower(txts)
#removing stopwords
txts=removeWords(txts,stopwords("english"))
txts=stripWhitespace(txts)
#lexicalize strings for lda()
docs=lexicalize(txts)
ads$txts=txts
temp_stm = textProcessor(documents=ads$txts,metadata=ads[,2:7])
outs_stm = prepDocuments(temp_stm$documents, temp_stm$vocab, temp_stm$meta)
#processing text for lda analysis
vocab = docs[[2]]
result=list()
#preset parameters for lda() models
alpha = 1.0
eta = 0.1
params = sample(c(-1, 1), k, replace=TRUE)
k=11
#processing text for lda analysis
vocab = docs[[2]]
result=list()
#preset parameters for lda() models
alpha = 1.0
eta = 0.1
params = sample(c(-1, 1), k, replace=TRUE)
#running the model!
result_2a=lda.collapsed.gibbs.sampler(docs[[1]],
k,
vocab,
100,
alpha = alpha,
eta = eta,
compute.log.likelihood=TRUE
)
lda_results <- top.topic.words(result_2a$topics,10)
colnames(lda_results) <- c("Topic 1", "Topic 2", "Topic 3", "Topic 4", "Topic 5", "Topic 6", "Topic 7",
"Topic 8", "Topic 9", "Topic 10", "Topic 11")
rownames(lda_results) <- c("#1", "#2", "#3", "#4", "#5", "#6" , "#7", "#8", "9", "#10")
tibble(lda_results)
lda_results
# annotation to predict
y=ads$party
result_2b=slda.em(documents=docs[[1]],
K=k,
vocab=vocab,
num.e.iterations=10,
num.m.iterations=4,
alpha=alpha, eta=eta,
annotations=y,
params,
variance=0.25,
lambda=1.0,
logistic=FALSE,
method="sLDA"
)
slda_party_results <- top.topic.words(result_2b$topics,10)
colnames(slda_party_results) <- c("Topic 1", "Topic 2", "Topic 3", "Topic 4", "Topic 5", "Topic 6", "Topic 7",
"Topic 8", "Topic 9", "Topic 10", "Topic 11")
rownames(slda_party_results) <- c("#1", "#2", "#3", "#4", "#5", "#6" , "#7", "#8", "9", "#10")
tibble(slda_party_results)
slda_party_results
# annotation to predict
y=ads$tone
result_2c=slda.em(documents=docs[[1]],
K=k,
vocab=vocab,
num.e.iterations=10,
num.m.iterations=4,
alpha=alpha, eta=eta,
annotations=y,
params,
variance=0.25,
lambda=1.0,
logistic=FALSE,
method="sLDA"
)
slda_tone_results <- top.topic.words(result_2c$topics,10)
colnames(slda_tone_results) <- c("Topic 1", "Topic 2", "Topic 3", "Topic 4", "Topic 5", "Topic 6", "Topic 7",
"Topic 8", "Topic 9", "Topic 10", "Topic 11")
rownames(slda_tone_results) <- c("#1", "#2", "#3", "#4", "#5", "#6" , "#7", "#8", "9", "#10")
tibble(slda_tone_results)
result_2d = stm(documents=outs_stm$documents,vocab=outs_stm$vocab,K=k,
prevalence=~party+tone,data=outs_stm$meta)
# (less than parsimonious) interface for collecting top 10 words =>
stm_results_2d <- t(labelTopics(model=result_2d, topics = NULL, n = 10, frexweight = 0.5)[1]$prob)
colnames(stm_results_2d) <- c("Topic 1", "Topic 2", "Topic 3", "Topic 4", "Topic 5", "Topic 6", "Topic 7",
"Topic 8", "Topic 9", "Topic 10", "Topic 11")
rownames(stm_results_2d) <- c("#1", "#2", "#3", "#4", "#5", "#6" , "#7", "#8", "9", "#10")
tibble(stm_results_2d)
result_2e = stm(documents=outs_stm$documents,vocab=outs_stm$vocab,K=k,
prevalence=~party+tone+office+policy+as.factor(state),data=outs_stm$meta)
# (less than parsimonious) interface for collecting top 10 words =>
stm_results_2e <- t(labelTopics(model=result_2e, topics = NULL, n = 10, frexweight = 0.5)[1]$prob)
colnames(stm_results_2e) <- c("Topic 1", "Topic 2", "Topic 3", "Topic 4", "Topic 5", "Topic 6", "Topic 7",
"Topic 8", "Topic 9", "Topic 10", "Topic 11")
rownames(stm_results_2e) <- c("#1", "#2", "#3", "#4", "#5", "#6" , "#7", "#8", "9", "#10")
tibble(stm_results_2e)
lda_results
slda_party_results
slda_tone_results
stm_results_2d
stm_results_2e
