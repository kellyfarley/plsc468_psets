for(i in 19:11)
{
pres_url=paste("https://www.congress.gov/house-communication/117th-congress/presidential-message/",i,"?s=3&r=", 20-i, sep='')
print(pres_url)
obs <- read_html(GET(pres_url, config(ssl_verifypeer = FALSE)))
nodes <- obs %>%
html_nodes("p")
text <- html_text(nodes)
#collecting abstracts
abstract <- text[3]
date <- text[2]
date <- gsub(date, pattern= "[a-z|A-Z]", replacement = "")
date <- gsub(date, pattern= "[:]", replacement = "")
#NEED COMMITTEE
thisDat <- c(url, date, abstract)
pres <- rbind(pres, thisDat)
}
rm(list = ls()) # clear global environ
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
# set working directory (change for each user)
wd <- "/Users/kellyfarley/Desktop/machine_learning/plsc468_psets"
#wd <- "/Users/numikatz/Documents/Senior_Year/Spring_22/PLSC_468/PLSC_468/plsc468_psets"
knitr::opts_knit$set(root.dir = wd)
# load libraries
library(RCurl)
library(stringr)
library(tm)
library(pryr)
library(corpus)
library(SnowballC)
library(textreadr)
library(httr)
library(rvest)
wd <- "/Users/numikatz/Documents/Senior_Year/Spring_22/PLSC_468/PLSC_468/plsc468_psets"
rm(list = ls()) # clear global environ
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
# set working directory (change for each user)
wd <- "/Users/kellyfarley/Desktop/machine_learning/plsc468_psets"
#wd <- "/Users/numikatz/Documents/Senior_Year/Spring_22/PLSC_468/PLSC_468/plsc468_psets"
knitr::opts_knit$set(root.dir = wd)
# load libraries
library(RCurl)
library(stringr)
library(tm)
library(pryr)
library(corpus)
library(SnowballC)
library(textreadr)
library(httr)
library(rvest)
exec <- data.frame(matrix(ncol=3,nrow=0))
tibble(exec)
exec <- data.frame(matrix(ncol=3,nrow=0))
names(exec) <-  c("url", "date", "abstract")
for (i in 3414:3413)
{
url <- paste("https://www.congress.gov/house-communication/117th-congress/executive-communication/",i,"?s=1&r=",3415-i, sep='')
print(url)
obs <- read_html(GET(url, config(ssl_verifypeer = FALSE)))
nodes <- obs %>%
html_nodes("p")
text <- html_text(nodes)
#collecting abstracts
abstract <- text[3]
#dates (this is gross code sorry!)
date <- text[2]
date <- gsub(date, pattern= "[a-z|A-Z]", replacement = "")
date <- gsub(date, pattern= "[:|,|.|-]", replacement = "")
thisDat <- c(url, date, abstract)
exec <- rbind(exec, thisDat)
}
#Goal: scrape abstract text, date, legislative committee(s) (if any)
exec <- data.frame(matrix(ncol=3,nrow=0))
pres <- data.frame(matrix(ncol=3,nrow=0))
for(i in 19:11)
{
pres_url=paste("https://www.congress.gov/house-communication/117th-congress/presidential-message/",i,"?s=3&r=", 20-i, sep='')
print(pres_url)
obs <- read_html(GET(pres_url, config(ssl_verifypeer = FALSE)))
nodes <- obs %>%
html_nodes("p")
text <- html_text(nodes)
#collecting abstracts
abstract <- text[3]
date <- text[2]
date <- gsub(date, pattern= "[a-z|A-Z]", replacement = "")
date <- gsub(date, pattern= "[:]", replacement = "")
#NEED COMMITTEE
comm_nodes <- obs %>%
html_nodes("li")
x <- grep("[0-9]{2}/[0-9]{2}/[0-9]{4}", nodes)
committee <- nodes[x]
committee <- gsub("<[^<>]*>", "", committee)
#removes exactly in parens
committee <- gsub("\n", "", committee, fixed = TRUE)
#removing date
committee <- gsub("[0-9]{2}/[0-9]{2}/[0-9]{4}", "", committee)
committee <- gsub(" — ", "", committee, fixed = TRUE)
#making df
thisDat <- c(url, date, abstract)
pres <- rbind(pres, thisDat)
names(pres) <-  c("url", "date", "abstract")
}
committee
comm_nodes <- obs %>%
html_nodes("li")
comm_nodes
x <- grep("[0-9]{2}/[0-9]{2}/[0-9]{4}", comm_nodes)
committee <- nodes[x]
pres <- data.frame(matrix(ncol=3,nrow=0))
for(i in 19:11)
{
pres_url=paste("https://www.congress.gov/house-communication/117th-congress/presidential-message/",i,"?s=3&r=", 20-i, sep='')
print(pres_url)
obs <- read_html(GET(pres_url, config(ssl_verifypeer = FALSE)))
nodes <- obs %>%
html_nodes("p")
text <- html_text(nodes)
#collecting abstracts
abstract <- text[3]
date <- text[2]
date <- gsub(date, pattern= "[a-z|A-Z]", replacement = "")
date <- gsub(date, pattern= "[:]", replacement = "")
#NEED COMMITTEE
comm_nodes <- obs %>%
html_nodes("li")
x <- grep("[0-9]{2}/[0-9]{2}/[0-9]{4}", comm_nodes)
committee <- comm_nodes[x]
committee <- gsub("<[^<>]*>", "", committee)
#removes exactly in parens
committee <- gsub("\n", "", committee, fixed = TRUE)
#removing date
committee <- gsub("[0-9]{2}/[0-9]{2}/[0-9]{4}", "", committee)
committee <- gsub(" — ", "", committee, fixed = TRUE)
#making df
thisDat <- c(url, date, abstract)
pres <- rbind(pres, thisDat)
names(pres) <-  c("url", "date", "abstract")
}
committee
pres <- data.frame(matrix(ncol=3,nrow=0))
for(i in 19:11)
{
pres_url=paste("https://www.congress.gov/house-communication/117th-congress/presidential-message/",i,"?s=3&r=", 20-i, sep='')
print(pres_url)
obs <- read_html(GET(pres_url, config(ssl_verifypeer = FALSE)))
nodes <- obs %>%
html_nodes("p")
text <- html_text(nodes)
#collecting abstracts
abstract <- text[3]
#COMMITTEE
comm_nodes <- obs %>%
html_nodes("li")
x <- grep("[0-9]{2}/[0-9]{2}/[0-9]{4}", comm_nodes)
committee <- comm_nodes[x]
committee <- gsub("<[^<>]*>", "", committee)
#removes exactly in parens
committee <- gsub("\n", "", committee, fixed = TRUE)
#removing date
committee <- gsub("[0-9]{2}/[0-9]{2}/[0-9]{4}", "", committee)
committee <- gsub(" — ", "", committee, fixed = TRUE)
#making df
thisDat <- c(url, date, abstract)
pres <- rbind(pres, thisDat)
names(pres) <-  c("url", "committee", "abstract")
}
View(pres)
pres <- data.frame(matrix(ncol=3,nrow=0))
for(i in 19:11)
{
pres_url=paste("https://www.congress.gov/house-communication/117th-congress/presidential-message/",i,"?s=3&r=", 20-i, sep='')
print(pres_url)
obs <- read_html(GET(pres_url, config(ssl_verifypeer = FALSE)))
nodes <- obs %>%
html_nodes("p")
text <- html_text(nodes)
#collecting abstracts
abstract <- text[3]
#COMMITTEE
comm_nodes <- obs %>%
html_nodes("li")
x <- grep("[0-9]{2}/[0-9]{2}/[0-9]{4}", comm_nodes)
committee <- comm_nodes[x]
committee <- gsub("<[^<>]*>", "", committee)
#removes exactly in parens
committee <- gsub("\n", "", committee, fixed = TRUE)
#removing date
committee <- gsub("[0-9]{2}/[0-9]{2}/[0-9]{4}", "", committee)
committee <- gsub(" — ", "", committee, fixed = TRUE)
#making df
thisDat <- c(url, committee, abstract)
pres <- rbind(pres, thisDat)
names(pres) <-  c("url", "committee", "abstract")
}
View(pres)
pres
pres[2]
pres[1:2]
pres <- data.frame(matrix(ncol=3,nrow=0))
for(i in 19:11)
{
pres_url=paste("https://www.congress.gov/house-communication/117th-congress/presidential-message/",i,"?s=3&r=", 20-i, sep='')
print(pres_url)
obs <- read_html(GET(pres_url, config(ssl_verifypeer = FALSE)))
nodes <- obs %>%
html_nodes("p")
text <- html_text(nodes)
#collecting abstracts
abstract <- text[3]
#COMMITTEE
comm_nodes <- obs %>%
html_nodes("li")
x <- grep("[0-9]{2}/[0-9]{2}/[0-9]{4}", comm_nodes)
committee <- comm_nodes[x]
committee <- gsub("<[^<>]*>", "", committee)
#removes exactly in parens
committee <- gsub("\n", "", committee, fixed = TRUE)
#removing date
committee <- gsub("[0-9]{2}/[0-9]{2}/[0-9]{4}", "", committee)
committee <- gsub(" — ", "", committee, fixed = TRUE)
#making df
thisDat <- c(url, committee, abstract)
pres <- rbind(pres, thisDat)
names(pres) <-  c("url", "committee", "abstract")
}
pres[2]
pres[1:2]
structure(committee)
#Goal: scrape abstract text, date, legislative committee(s) (if any)
exec <- data.frame(matrix(ncol=3,nrow=0))
for (i in 3414:3413)
{
url <- paste("https://www.congress.gov/house-communication/117th-congress/executive-communication/",i,"?s=1&r=",3415-i, sep='')
print(url)
obs <- read_html(GET(url, config(ssl_verifypeer = FALSE)))
nodes <- obs %>%
html_nodes("p")
text <- html_text(nodes)
#collecting abstracts
abstract <- text[3]
#committees
comm_nodes <- obs %>%
html_nodes("li")
x <- grep("[0-9]{2}/[0-9]{2}/[0-9]{4}", comm_nodes)
committee <- comm_nodes[x]
committee <- gsub("<[^<>]*>", "", committee)
#removes exactly in parens
committee <- gsub("\n", "", committee, fixed = TRUE)
#removing date
committee <- gsub("[0-9]{2}/[0-9]{2}/[0-9]{4}", "", committee)
committee <- gsub(" — ", "", committee, fixed = TRUE)
thisDat <- c(url, date, abstract)
exec <- rbind(exec, thisDat)
names(exec) <-  c("url", "date", "abstract")
}
committee
View(exec)
exec <- data.frame(matrix(ncol=3,nrow=0))
# will need to add 4th column for committee
for (i in 3414:3413)
{
url <- paste("https://www.congress.gov/house-communication/117th-congress/executive-communication/",i,"?s=1&r=",3415-i, sep='')
print(url)
obs <- read_html(GET(url, config(ssl_verifypeer = FALSE)))
nodes <- obs %>%
html_nodes("p")
text <- html_text(nodes)
#collecting abstracts
abstract <- text[3]
#committees
comm_nodes <- obs %>%
html_nodes("li")
x <- grep("[0-9]{2}/[0-9]{2}/[0-9]{4}", comm_nodes)
committee <- comm_nodes[x]
committee <- gsub("<[^<>]*>", "", committee)
#removes exactly in parens
committee <- gsub("\n", "", committee, fixed = TRUE)
#removing date
committee <- gsub("[0-9]{2}/[0-9]{2}/[0-9]{4}", "", committee)
committee <- gsub(" — ", "", committee, fixed = TRUE)
thisDat <- c(url, committee, abstract)
exec <- rbind(exec, thisDat)
names(exec) <-  c("url", "committee", "abstract")
}
View(exec)
pet <- data.frame(matrix(ncol=3,nrow=0))
for(i in 96:94)
{
pet_url=paste("https://www.congress.gov/house-communication/117th-congress/petition/",i,"?s=3&r=", 97-i, sep='')
print(pet_url)
obs <- read_html(GET(pet_url, config(ssl_verifypeer = FALSE)))
nodes <- obs %>%
html_nodes("p")
text <- html_text(nodes)
#collecting abstracts
abstract <- text[3]
#committees
comm_nodes <- obs %>%
html_nodes("li")
x <- grep("[0-9]{2}/[0-9]{2}/[0-9]{4}", comm_nodes)
committee <- comm_nodes[x]
committee <- gsub("<[^<>]*>", "", committee)
committee <- gsub("\n", "", committee, fixed = TRUE)
committee <- gsub("[0-9]{2}/[0-9]{2}/[0-9]{4}", "", committee)
committee <- gsub(" — ", "", committee, fixed = TRUE)
#dataframe
thisDat <- c(url, committee, abstract)
pet <<- rbind(pet, thisDat)
names(pet) <-  c("url", "committee", "abstract")
}
View(pet)
mem <- data.frame(matrix(ncol=3,nrow=0))
for(i in 138:137)
{
mem_url=paste("https://www.congress.gov/house-communication/117th-congress/memorial/",i,"?s=3&r=", 139-i, sep='')
print(mem_url)
obs <- read_html(GET(mem_url, config(ssl_verifypeer = FALSE)))
nodes <- obs %>%
html_nodes("p")
text <- html_text(nodes)
#collecting abstracts
abstract <- text[3]
#committees
comm_nodes <- obs %>%
html_nodes("li")
x <- grep("[0-9]{2}/[0-9]{2}/[0-9]{4}", comm_nodes)
committee <- comm_nodes[x]
committee <- gsub("<[^<>]*>", "", committee)
committee <- gsub("\n", "", committee, fixed = TRUE)
committee <- gsub("[0-9]{2}/[0-9]{2}/[0-9]{4}", "", committee)
committee <- gsub(" — ", "", committee, fixed = TRUE)
thisDat <- c(url, committee, abstract)
mem <- rbind(mem, thisDat)
names(mem) <-  c("url", "committee", "abstract")
}
committee
View(mem)
committee
thisDat
mem
str(thisDat)
mem <- data.frame(matrix(ncol=3,nrow=0))
for(i in 138:137)
{
mem_url=paste("https://www.congress.gov/house-communication/117th-congress/memorial/",i,"?s=3&r=", 139-i, sep='')
print(mem_url)
obs <- read_html(GET(mem_url, config(ssl_verifypeer = FALSE)))
nodes <- obs %>%
html_nodes("p")
text <- html_text(nodes)
#collecting abstracts
abstract <- text[3]
#committees
comm_nodes <- obs %>%
html_nodes("li")
x <- grep("[0-9]{2}/[0-9]{2}/[0-9]{4}", comm_nodes)
committee <- comm_nodes[x]
committee <- gsub("<[^<>]*>", "", committee)
committee <- gsub("\n", "", committee, fixed = TRUE)
committee <- gsub("[0-9]{2}/[0-9]{2}/[0-9]{4}", "", committee)
committee <- gsub(" — ", "", committee, fixed = TRUE)
thisDat <- c(url, committee, abstract)
mem <- rbind(mem, thisDat)
names(mem) <-  c("url", "committee", "abstract")
}
View(mem)
View(mem)
pet <- data.frame(matrix(ncol=3,nrow=0))
for(i in 96:94)
{
pet_url=paste("https://www.congress.gov/house-communication/117th-congress/petition/",i,"?s=3&r=", 97-i, sep='')
print(pet_url)
obs <- read_html(GET(pet_url, config(ssl_verifypeer = FALSE)))
nodes <- obs %>%
html_nodes("p")
text <- html_text(nodes)
#collecting abstracts
abstract <- text[3]
#committees
comm_nodes <- obs %>%
html_nodes("li")
x <- grep("[0-9]{2}/[0-9]{2}/[0-9]{4}", comm_nodes)
committee <- comm_nodes[x]
committee <- gsub("<[^<>]*>", "", committee)
committee <- gsub("\n", "", committee, fixed = TRUE)
committee <- gsub("[0-9]{2}/[0-9]{2}/[0-9]{4}", "", committee)
committee <- gsub(" — ", "", committee, fixed = TRUE)
#dataframe
thisDat <- c(url, committee, abstract)
pet <<- rbind(pet, thisDat)
names(pet) <-  c("url", "committee", "abstract")
}
View(pet)
pres <- data.frame(matrix(ncol=3,nrow=0))
for(i in 19:11)
{
pres_url=paste("https://www.congress.gov/house-communication/117th-congress/presidential-message/",i,"?s=3&r=", 20-i, sep='')
print(pres_url)
obs <- read_html(GET(pres_url, config(ssl_verifypeer = FALSE)))
nodes <- obs %>%
html_nodes("p")
text <- html_text(nodes)
#collecting abstracts
abstract <- text[3]
#COMMITTEE
comm_nodes <- obs %>%
html_nodes("li")
x <- grep("[0-9]{2}/[0-9]{2}/[0-9]{4}", comm_nodes)
committee <- comm_nodes[x]
committee <- gsub("<[^<>]*>", "", committee)
#removes exactly in parens
committee <- gsub("\n", "", committee, fixed = TRUE)
#removing date
committee <- gsub("[0-9]{2}/[0-9]{2}/[0-9]{4}", "", committee)
committee <- gsub(" — ", "", committee, fixed = TRUE)
#making df
thisDat <- c(url, committee, abstract)
pres <- rbind(pres, thisDat)
names(pres) <-  c("url", "committee", "abstract")
}
View(pres)
rm(list = ls()) # clear global environ
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
# set working directory (change for each user)
wd <- "/Users/kellyfarley/Desktop/machine_learning/plsc468_psets"
#wd <- "/Users/numikatz/Documents/Senior_Year/Spring_22/PLSC_468/PLSC_468/plsc468_psets"
knitr::opts_knit$set(root.dir = wd)
# load libraries
library(RCurl)
library(stringr)
library(tm)
library(pryr)
library(corpus)
library(SnowballC)
library(textreadr)
library(httr)
library(rvest)
wd <- "/Users/numikatz/Documents/Senior_Year/Spring_22/PLSC_468/PLSC_468/plsc468_psets"
rm(list = ls()) # clear global environ
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
# set working directory (change for each user)
wd <- "/Users/kellyfarley/Desktop/machine_learning/plsc468_psets"
#wd <- "/Users/numikatz/Documents/Senior_Year/Spring_22/PLSC_468/PLSC_468/plsc468_psets"
knitr::opts_knit$set(root.dir = wd)
# load libraries
library(RCurl)
library(stringr)
library(tm)
library(pryr)
library(corpus)
library(SnowballC)
library(textreadr)
library(httr)
library(rvest)
pres <- data.frame(matrix(ncol=3,nrow=0))
for(i in 19:1)
{
pres_url=paste("https://www.congress.gov/house-communication/117th-congress/presidential-message/",i,"?s=3&r=", 20-i, sep='')
print(pres_url)
obs <- read_html(GET(pres_url, config(ssl_verifypeer = FALSE)))
nodes <- obs %>%
html_nodes("p")
text <- html_text(nodes)
#collecting abstracts
abstract <- text[3]
#COMMITTEE
comm_nodes <- obs %>%
html_nodes("li")
x <- grep("[0-9]{2}/[0-9]{2}/[0-9]{4}", comm_nodes)
committee <- comm_nodes[x]
committee <- gsub("<[^<>]*>", "", committee)
#removes exactly in parens
committee <- gsub("\n", "", committee, fixed = TRUE)
#removing date
committee <- gsub("[0-9]{2}/[0-9]{2}/[0-9]{4}", "", committee)
committee <- gsub(" — ", "", committee, fixed = TRUE)
committee <- paste(committee, collapse=", ")
#making df
thisDat <- c(url, committee, abstract)
pres <- rbind(pres, thisDat)
names(pres) <-  c("url", "committee", "abstract")
}
pres <- data.frame(matrix(ncol=3,nrow=0))
for(i in 19:1)
{
pres_url=paste("https://www.congress.gov/house-communication/117th-congress/presidential-message/",i,"?s=3&r=", 20-i, sep='')
print(pres_url)
obs <- read_html(GET(pres_url, config(ssl_verifypeer = FALSE)))
nodes <- obs %>%
html_nodes("p")
text <- html_text(nodes)
#collecting abstracts
abstract <- text[3]
#COMMITTEE
comm_nodes <- obs %>%
html_nodes("li")
x <- grep("[0-9]{2}/[0-9]{2}/[0-9]{4}", comm_nodes)
committee <- comm_nodes[x]
committee <- gsub("<[^<>]*>", "", committee)
#removes exactly in parens
committee <- gsub("\n", "", committee, fixed = TRUE)
#removing date
committee <- gsub("[0-9]{2}/[0-9]{2}/[0-9]{4}", "", committee)
committee <- gsub(" — ", "", committee, fixed = TRUE)
committee <- paste(committee, collapse=", ")
#making df
thisDat <- c(url, committee, abstract)
pres <- rbind(pres, thisDat)
names(pres) <-  c("url", "committee", "abstract")
}
rm(list = ls()) # clear global environ
