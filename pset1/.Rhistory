findAssocs(dtdm, freq1972, 0.9999674)
findAssocs(dtdm, freq1972, 0.9999675)
findAssocs(dtdm, freq1972, 0.9999676)
findAssocs(dtdm, freq1972, 0.9999675)
findAssocs(dtdm, freq1972, 0.99996759)
# dem tdm
dtdm <- TermDocumentMatrix(corpus[1:3])
# republican tdm
rtdm <- TermDocumentMatrix(corpus[4:6])
freq1972 <- "state"
findAssocs(dtdm, freq1972, 0.99996)
findAssocs(rtdm, freq1972, 0.9984)
# dem tdm
dtdm <- TermDocumentMatrix(corpus[1:3])
# republican tdm
rtdm <- TermDocumentMatrix(corpus[4:6])
freq1972 <- "state"
findAssocs(dtdm, freq1972, 0.999)
findAssocs(rtdm, freq1972, 0.999)
# dem tdm
dtdm <- TermDocumentMatrix(corpus[1:3])
# republican tdm
rtdm <- TermDocumentMatrix(corpus[4:6])
freq1972 <- "state"
findAssocs(dtdm, freq1972, 0.99)
findAssocs(rtdm, freq1972, 0.99)
findAssocs(dtdm, freq1972, 0.9999)
findAssocs(dtdm, freq1972, 0.99999)
findAssocs(dtdm, freq1972, 0.9999)
findAssocs(dtdm, freq1972, 0.99998)
findAssocs(dtdm, freq1972, 0.99995)
findAssocs(dtdm, freq1972, 0.99996)
findAssocs(dtdm, freq1972, 0.99997)
findAssocs(dtdm, freq1972, 0.99996)
findAssocs(dtdm, freq1972, 0.99995)
findAssocs(dtdm, freq1972, 0.99997)
findAssocs(dtdm, freq1972, 0.99996)
findAssocs(dtdm, freq1972, 0.999969)
findAssocs(dtdm, freq1972, 0.999965)
findAssocs(dtdm, freq1972, 0.999966)
findAssocs(dtdm, freq1972, 0.999967)
findAssocs(dtdm, freq1972, 0.999968)
findAssocs(dtdm, freq1972, 0.999967)
findAssocs(dtdm, freq1972, 0.9999679)
findAssocs(dtdm, freq1972, 0.9999675)
findAssocs(dtdm, freq1972, 0.9999677)
findAssocs(dtdm, freq1972, 0.9999676)
findAssocs(dtdm, freq1972, 0.9999679)
findAssocs(dtdm, freq1972, 0.9999675)
findAssocs(dtdm, freq1972, 0.9999676)
findAssocs(dtdm, freq1972, 0.9999675)
findAssocs(dtdm, freq1972, 0.99996759)
temp <- findAssocs(dtdm, freq1972, 0.99)
max(temp)
str(temp)
temp$state
temp$state[1]
max(temp$state)
which(temp$state==max(temp$state))
temp$state[which(temp$state==max(temp$state))]
findAssocs(dtdm, freq1972, 0.99)
findAssocs(rtdm, freq1972, 0.99)
findAssocs(dtdm, freq1972, 0.99)
findAssocs(dtdm, freq1972, 0.99)
findAssocs(dtdm, freq1972, 0.999)
findAssocs(dtdm, freq1972, 0.9999)
findAssocs(dtdm, freq1972, 0.99999)
findAssocs(dtdm, freq1972, 0.99998)
findAssocs(dtdm, freq1972, 0.99996)
findAssocs(dtdm, freq1972, 0.99997)
findAssocs(dtdm, freq1972, 0.99996)
findAssocs(dtdm, freq1972, 0.999965)
findAssocs(dtdm, freq1972, 0.999967)
findAssocs(dtdm, freq1972, 0.999969)
findAssocs(dtdm, freq1972, 0.999968)
findAssocs(dtdm, freq1972, 0.999967)
findAssocs(dtdm, freq1972, 0.9999675)
findAssocs(dtdm, freq1972, 0.9999677)
findAssocs(dtdm, freq1972, 0.9999676)
findAssocs(dtdm, freq1972, 0.9999675)
findAssocs(dtdm, freq1972, 0.99996759)
findAssocs(dtdm, freq1972, 0.99996758)
findAssocs(dtdm, freq1972, 0.99996757)
findAssocs(dtdm, freq1972, 0.99996756)
findAssocs(dtdm, freq1972, 0.99996755)
findAssocs(dtdm, freq1972, 0.999967559)
findAssocs(dtdm, freq1972, 0.999967558)
findAssocs(dtdm, freq1972, 0.999967557)
findAssocs(dtdm, freq1972, 0.999967556)
findAssocs(dtdm, freq1972, 0.999967555)
findAssocs(dtdm, freq1972, 0.999967554)
findAssocs(dtdm, freq1972, 0.999967553)
findAssocs(dtdm, freq1972, 0.999967552)
findAssocs(dtdm, freq1972, 0.999967551)
findAssocs(dtdm, freq1972, 0.999967552)
findAssocs(dtdm, freq1972, 0.999967551)
findAssocs(dtdm, freq1972, 0.9999675515)
findAssocs(dtdm, freq1972, 0.9999675517)
findAssocs(dtdm, freq1972, 0.9999675516)
findAssocs(dtdm, freq1972, 0.99996755169)
findAssocs(dtdm, freq1972, 0.99996755165)
findAssocs(dtdm, freq1972, 0.99996755163)
findAssocs(dtdm, freq1972, 0.99996755162)
findAssocs(dtdm, freq1972, 0.99996755161)
findAssocs(dtdm, freq1972, 0.9999675516)
findAssocs(dtdm, freq1972, 0.99996755161)
findAssocs(dtdm, freq1972, 0.9999)
findAssocs(rtdm, freq1972, 0.9999)
findAssocs(rtdm, freq1972, 0.999
)
findAssocs(rtdm, freq1972, 0.998
)
findAssocs(rtdm, freq1972, 0.998)
findAssocs(rtdm, freq1972, 0.999)
findAssocs(rtdm, freq1972, 0.9989)
findAssocs(rtdm, freq1972, 0.9988)
findAssocs(rtdm, freq1972, 0.9985)
findAssocs(rtdm, freq1972, 0.9984)
findAssocs(rtdm, freq1972, 0.9985)
findAssocs(rtdm, freq1972, 0.9984)
findAssocs(dtdm, freq1972, 0.9999)
?findAssocs
findAssocs(dtdm, freq1972, 0.9999)
temp <- findAssocs(dtdm, freq1972, 0.9999)
str(temp)
temp2 <- unlist(temp)
temp2
str(temp2)
temp2$coefficients
temp2$coefficients[["state.civil"]]
temp2[[coefficients]]
is.atomic(temp2)
temp2[[state.civil]]
temp2[["state.civil"]]
temp2[["state.civil"]] > temp2[["state.feder"]]
temp3 <- as.data.frame(temp2)
temp3
sort(temp3)
temp3[order(temp2),]
temp3
topDem <- findAssocs(dtdm, freq1972, 0.9999)
topDem <- as.data.frame(unlist(topDem))
topDem
topDem <- findAssocs(dtdm, freq1972, 0.9999)
topDem <- as.data.frame(unlist(topDem), names="association")
topDem
str(topDem)
names(topDem)
topDem <- findAssocs(dtdm, freq1972, 0.9999)
topDem <- as.data.frame(unlist(topDem))
names(topDem) <- "association"
topDem
View(topDem)
temp2[["state.civil"]] == temp2[["state.feder"]]
topDem <- findAssocs(dtdm, freq1972, 0.9999)
topDem <- as.data.frame(unlist(topDem))
names(topDem) <- "association"
topDem <- topDem[order(topDem$association),]
topDem
topDem
View(topDem)
topDem <- findAssocs(dtdm, freq1972, 0.9999)
topDem <- as.data.frame(unlist(topDem))
names(topDem) <- "association"
topDem <- topDem[order(association),]
topDem <- findAssocs(dtdm, freq1972, 0.9999)
topDem <- as.data.frame(unlist(topDem))
names(topDem) <- "association"
topDem
topDem[order(association),]
topDem[order(topDem$association),]
topDem[order(topDem$association),]
str(topDem)
findAssocs(rtdm, freq1972, 0.9984)
findAssocs(rtdm, freq1972, 0.9985)
findAssocs(rtdm, freq1972, 0.9984)
topDem <- findAssocs(dtdm, freq1972, 0.9999)
findAssocs(dtdm, freq1972, 0.9999)
findAssocs(rtdm, freq1972, 0.9984)
findAssocs(rtdm, freq1972, 0.9985)
findAssocs(rtdm, freq1972, 0.99849)
findAssocs(rtdm, freq1972, 0.99842)
findAssocs(rtdm, freq1972, 0.99843)
findAssocs(rtdm, freq1972, 0.99844)
findAssocs(rtdm, freq1972, 0.99845)
findAssocs(rtdm, freq1972, 0.99844)
findAssocs(rtdm, freq1972, 0.998449)
findAssocs(rtdm, freq1972, 0.998445)
findAssocs(rtdm, freq1972, 0.998443)
findAssocs(rtdm, freq1972, 0.998442)
findAssocs(rtdm, freq1972, 0.9984425)
findAssocs(rtdm, freq1972, 0.9984426)
findAssocs(rtdm, freq1972, 0.9984429)
findAssocs(rtdm, freq1972, 0.9984428)
findAssocs(rtdm, freq1972, 0.998)
findAssocs(rtdm, freq1972, 0.9989)
findAssocs(rtdm, freq1972, 0.9986)
findAssocs(rtdm, freq1972, 0.9983)
findAssocs(rtdm, freq1972, 0.9984)
findAssocs(rtdm, freq1972, 0.9985)
findAssocs(rtdm, freq1972, 0.9984)
findAssocs(dtdm, freq1972, 0.9999)
findAssocs(dtdm, freq1972, 0.9998)
findAssocs(dtdm, freq1972, 0.9995)
findAssocs(dtdm, freq1972, 0.9993)
findAssocs(dtdm, freq1972, 0.9992)
findAssocs(dtdm, freq1972, 0.999)
findAssocs(dtdm, freq1972, 0.995)
findAssocs(dtdm, freq1972, 0.994)
rm(list = ls()) # clear global environ
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
wd <- "/Users/kellyfarley/Desktop/Farley, Katz, Wang - Pset 1 - PLSC 468"
knitr::opts_knit$set(root.dir = wd)
# load libraries
library(RCurl)
library(stringr)
library(tm)
library(pryr)
library(corpus)
library(SnowballC)
library(textreadr)
library(httr)
library(rvest)
years <- 1968+4*0:2
urlsR <- paste("https://maineanencyclopedia.com/republican-party-platform-",years,"/",sep='')
urlsD <- paste("https://maineanencyclopedia.com/democratic-party-platform-",years,"/",sep='')
# combining urls
urls <- c(urlsD, urlsR)
# print urls
paste(urls)
cleantxt <- NULL
for (i in 1:length(urls)){
txts <- getURL(urls[i])
# remove html attributes
txts <- gsub("<[^<>]*>", "", txts)
txts <- gsub("\t", "", txts, fixed = TRUE)
txts <- gsub("\n", "", txts, fixed = TRUE)
txts <- gsub("&#82[0-9]{2};", "", txts)
# removing large amounts of white space
txts <- gsub("\\s{2,}", "", txts)
# removing text before preamble begins
txts <- gsub(".*description", "", txts) # "description" tag always comes right before content
txts <- gsub(".*\\(\\);\\}\\);", "", txts) # another tag before content
txts <- gsub(".*(?i)[aA-zZ]preamble", "", txts)
txts <-gsub(".*;+(?i)preamble", "", txts)
# removing text after party platform ends
txts <- gsub("Source: .*", "", txts)
# removing extra characters
txts <- gsub("â€\\S?", "", txts)
txts <- gsub("*", "", txts, fixed = TRUE)
# adding final cleaned text
cleantxt[i] <- txts
}
# print first entry to demonstrate cleaning
cleantxt[1]
# download htmlToText function
download.file("https://drive.google.com/u/0/uc?id=1LuMKRhzPBHWGzVM-Bs64n_ciNMoHHbPd", paste(wd, "/functions/htmlToText.R", sep=""))
# source htmlToText function
source(paste(wd, "/functions/htmlToText.R", sep=""))
do.run=T
if(do.run==T){
txts_1b=array(NA,length(urls))
for(i in 1:length(urls)){
txts_1b[i]=htmlToText(urls[i])
}
}
txts_1b[1]
# creating a corpus
corpus <- Corpus(VectorSource(cleantxt))
corpus_raw <- corpus
# stem using porter algorithm
corpus <- tm_map(corpus, stemDocument)
# remove uppercase
corpus <- tm_map(corpus, tolower)
# remove stop words
corpus <- tm_map(corpus, removeWords, stopwords("english"))
# remove punctuation
corpus <- tm_map(corpus, removePunctuation)
# remove extra white space
corpus <- tm_map(corpus, stripWhitespace)
# remove numbers
corpus <- tm_map(corpus, removeNumbers)
# creating a term document matrix
tdm <- TermDocumentMatrix(corpus)
# combining the tdms of the 6 platforms into one matrix
m <- as.matrix(tdm)
# reorganizing the matrix to get the most common words
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
head(d, 20)
# reorganizing the maatrix to get the least common words
v2 <- sort(rowSums(m),decreasing=FALSE)
d2 <- data.frame(word = names(v2),freq=v2)
head(d2, 20)
freq10 <- findMostFreqTerms(tdm, 10)
freq10
# extracting the 10 most frequent words of each party platform
D1968 <- names(freq10[1][[1]])
D1972 <- names(freq10[2][[1]])
D1976 <- names(freq10[3][[1]])
R1968 <- names(freq10[4][[1]])
R1972 <- names(freq10[5][[1]])
R1976 <- names(freq10[6][[1]])
# words that repeat among the 3 R platforms
Reduce(intersect, list(R1968,R1972,R1976))
# words that repeat among the 3 D platforms
Reduce(intersect, list(D1968,D1972,D1976))
# words that repeat across the 1972 D and R platforms
Reduce(intersect, list(D1972, R1972))
# recall that D 1972 is the 2nd text in the corpus
freq10[2]
# recall that R 1972 is the 5th text in the corpus
freq10[5]
# dem tdm
dtdm <- TermDocumentMatrix(corpus[1:3])
# republican tdm
rtdm <- TermDocumentMatrix(corpus[4:6])
freq1972 <- "state"
findAssocs(dtdm, freq1972, 0.99)
findAssocs(rtdm, freq1972, 0.99)
# democratic platform
dHighestAssoc <- findAssocs(dtdm, freq1972, 0.999)
dHighestAssoc <- unlist(dHighestAssoc)
dHighestAssoc <- names(dHighestAssoc)
dHighestAssoc <- gsub("^.*\\.","", dHighestAssoc) # gives list of words with association of approximately 1
dHighestAssoc <- as.data.frame(dHighestAssoc)
names(dHighestAssoc) <- "word"
dHighestAssocFreq <- merge(dHighestAssoc, d, by="word") # merge with frequency df
dHighestAssocFreq <- dHighestAssocFreq[order(-dHighestAssocFreq$freq),] # order by frequency
dHighestAssocFreq[c(1:2),] # get top two words
# republican platform
rHighestAssoc <- findAssocs(rtdm, freq1972, 0.9984)
rHighestAssoc <- unlist(rHighestAssoc)
rHighestAssoc <- names(rHighestAssoc)
rHighestAssoc <- gsub("^.*\\.","", rHighestAssoc) # gives list of words with association of approximately 1
rHighestAssoc <- as.data.frame(rHighestAssoc)
names(rHighestAssoc) <- "word"
rHighestAssocFreq <- merge(rHighestAssoc, d, by="word") # merge with frequency df
rHighestAssocFreq <- rHighestAssocFreq[order(-rHighestAssocFreq$freq),] # order by frequency
rHighestAssocFreq[c(1:2),]
# Goal: scrape url, abstract text,legislative committee(s) (if any)
# Process: initialize data frame; get urls; collect abstracts from "p" tag; collect committees from "li" tag; clean committee text; add to data frame
matNames <- c("URL", "Abstract", "Committee") # to be used for all matrices
# EXECUTIVE
exec <- data.frame(matrix(ncol=3,nrow=0))
for (i in 3414:1)
{
url <- paste("https://www.congress.gov/house-communication/117th-congress/executive-communication/",i,"?s=1&r=",3415-i, sep='')
obs <- read_html(GET(url, config(ssl_verifypeer = FALSE)))
# collecting abstracts
nodes <- obs %>%
html_nodes("p")
text <- html_text(nodes)
abstract <- text[3]
# collecting committees
comm_nodes <- obs %>%
html_nodes("li")
# cleaning committees
x <- grep("[0-9]{2}/[0-9]{2}/[0-9]{4}", comm_nodes)
committee <- comm_nodes[x]
committee <- gsub("<[^<>]*>", "", committee)
committee <- gsub("\n", "", committee, fixed = TRUE)
committee <- gsub("[0-9]{2}/[0-9]{2}/[0-9]{4}", "", committee)
committee <- gsub(" — ", "", committee, fixed = TRUE)
committee <- paste(committee, collapse=", ") # to account for multiple committees
# add to df
thisDat <- c(url, abstract, committee)
exec <- rbind(exec, thisDat)
names(exec) <-  matNames
}
dirname(getActiveDocumentContext()$path
)
setwd(getSrcDirectory()[1])
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
dirname(parent.frame(2)$ofile)
dirname(parent.frame(2)$farley,katz,wang-pset1.Rmd)
rm(list = ls()) # clear global environ
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
# set working directory (change for each user)
#wd <- "/Users/kellyfarley/Desktop/machine_learning/plsc468_psets"
#wd <- "/Users/numikatz/Documents/Senior_Year/Spring_22/PLSC_468/PLSC_468/plsc468_psets"
wd <- "/Users/kellyfarley/Desktop/Farley, Katz, Wang - Pset 1 - PLSC 468"
knitr::opts_knit$set(root.dir = wd)
# load libraries
library(RCurl)
library(stringr)
library(tm)
library(pryr)
library(corpus)
library(SnowballC)
library(textreadr)
library(httr)
library(rvest)
# get urls for both republican and democrat platforms for 1968, 1972, 1976
years <- 1968+4*0:2
urlsR <- paste("https://maineanencyclopedia.com/republican-party-platform-",years,"/",sep='')
urlsD <- paste("https://maineanencyclopedia.com/democratic-party-platform-",years,"/",sep='')
# combining urls
urls <- c(urlsD, urlsR)
# print urls
paste(urls)
# looping thru the 6 party platforms
cleantxt <- NULL
for (i in 1:length(urls)){
txts <- getURL(urls[i])
# remove html attributes
txts <- gsub("<[^<>]*>", "", txts)
txts <- gsub("\t", "", txts, fixed = TRUE)
txts <- gsub("\n", "", txts, fixed = TRUE)
txts <- gsub("&#82[0-9]{2};", "", txts)
# removing large amounts of white space
txts <- gsub("\\s{2,}", "", txts)
# removing text before preamble begins
txts <- gsub(".*description", "", txts) # "description" tag always comes right before content
txts <- gsub(".*\\(\\);\\}\\);", "", txts) # another tag before content
txts <- gsub(".*(?i)[aA-zZ]preamble", "", txts)
txts <-gsub(".*;+(?i)preamble", "", txts)
# removing text after party platform ends
txts <- gsub("Source: .*", "", txts)
# removing extra characters
txts <- gsub("â€\\S?", "", txts)
txts <- gsub("*", "", txts, fixed = TRUE)
# adding final cleaned text
cleantxt[i] <- txts
}
# print first entry to demonstrate cleaning
cleantxt[1]
# download htmlToText function
download.file("https://drive.google.com/u/0/uc?id=1LuMKRhzPBHWGzVM-Bs64n_ciNMoHHbPd", paste(wd, "/functions/htmlToText.R", sep=""))
# source htmlToText function
source(paste(wd, "/functions/htmlToText.R", sep=""))
do.run=T
if(do.run==T){
txts_1b=array(NA,length(urls))
for(i in 1:length(urls)){
txts_1b[i]=htmlToText(urls[i])
}
}
txts_1b[1]
# creating a corpus
corpus <- Corpus(VectorSource(cleantxt))
corpus_raw <- corpus
# stem using porter algorithm
corpus <- tm_map(corpus, stemDocument)
# remove uppercase
corpus <- tm_map(corpus, tolower)
# remove stop words
corpus <- tm_map(corpus, removeWords, stopwords("english"))
# remove punctuation
corpus <- tm_map(corpus, removePunctuation)
# remove extra white space
corpus <- tm_map(corpus, stripWhitespace)
# remove numbers
corpus <- tm_map(corpus, removeNumbers)
# creating a term document matrix
tdm <- TermDocumentMatrix(corpus)
# combining the tdms of the 6 platforms into one matrix
m <- as.matrix(tdm)
# reorganizing the matrix to get the most common words
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
head(d, 20)
# reorganizing the maatrix to get the least common words
v2 <- sort(rowSums(m),decreasing=FALSE)
d2 <- data.frame(word = names(v2),freq=v2)
head(d2, 20)
freq10 <- findMostFreqTerms(tdm, 10)
freq10
# extracting the 10 most frequent words of each party platform
D1968 <- names(freq10[1][[1]])
D1972 <- names(freq10[2][[1]])
D1976 <- names(freq10[3][[1]])
R1968 <- names(freq10[4][[1]])
R1972 <- names(freq10[5][[1]])
R1976 <- names(freq10[6][[1]])
# words that repeat among the 3 R platforms
Reduce(intersect, list(R1968,R1972,R1976))
# words that repeat among the 3 D platforms
Reduce(intersect, list(D1968,D1972,D1976))
# words that repeat across the 1972 D and R platforms
Reduce(intersect, list(D1972, R1972))
# recall that D 1972 is the 2nd text in the corpus
freq10[2]
# recall that R 1972 is the 5th text in the corpus
freq10[5]
# dem tdm
dtdm <- TermDocumentMatrix(corpus[1:3])
# republican tdm
rtdm <- TermDocumentMatrix(corpus[4:6])
freq1972 <- "state"
findAssocs(dtdm, freq1972, 0.99)
findAssocs(rtdm, freq1972, 0.99)
# democratic platform
dHighestAssoc <- findAssocs(dtdm, freq1972, 0.999)
dHighestAssoc <- unlist(dHighestAssoc)
dHighestAssoc <- names(dHighestAssoc)
dHighestAssoc <- gsub("^.*\\.","", dHighestAssoc) # gives list of words with association of approximately 1
dHighestAssoc <- as.data.frame(dHighestAssoc)
names(dHighestAssoc) <- "word"
dHighestAssocFreq <- merge(dHighestAssoc, d, by="word") # merge with frequency df
dHighestAssocFreq <- dHighestAssocFreq[order(-dHighestAssocFreq$freq),] # order by frequency
dHighestAssocFreq[c(1:2),] # get top two words
# republican platform
rHighestAssoc <- findAssocs(rtdm, freq1972, 0.9984)
rHighestAssoc <- unlist(rHighestAssoc)
rHighestAssoc <- names(rHighestAssoc)
rHighestAssoc <- gsub("^.*\\.","", rHighestAssoc) # gives list of words with association of approximately 1
rHighestAssoc <- as.data.frame(rHighestAssoc)
names(rHighestAssoc) <- "word"
rHighestAssocFreq <- merge(rHighestAssoc, d, by="word") # merge with frequency df
rHighestAssocFreq <- rHighestAssocFreq[order(-rHighestAssocFreq$freq),] # order by frequency
rHighestAssocFreq[c(1:2),]
