dates <- text[2]
}
library(rvest)
for (i in 3395:3390)
{
url=paste("https://www.congress.gov/house-communication/117th-congress/executive-communication/",i,"?s=3&r=",4000-i, sep='')
print(url)
obs <- read_html(GET(url, config(ssl_verifypeer = FALSE)))
nodes <- obs %>%
html_nodes("p")
text <- html_text(nodes)
#collecting abstracts
abstracts <- text[4]
#dates (this is gross code sorry!)
dates <- text[2]
}
abstracts
dates
for(i in 19:1)
{
pres_url=paste("https://www.congress.gov/house-communication/117th-congress/presidential-message/",i,"?s=3&r=", 20-i, sep='')
print(pres_url)
obs <- read_html(GET(pres_url, config(ssl_verifypeer = FALSE)))
nodes <- obs %>%
html_nodes("p")
text <- html_text(nodes)
#collecting abstracts - need to collect for each url
abstracts <- nodes[3]
#dates
dates <- texts[2]
dates <- gsub(dates, pattern = "[a-z |A-Z ]", replace = "")
}
for (i in 3395:3390)
{
url=paste("https://www.congress.gov/house-communication/117th-congress/executive-communication/",i,"?s=3&r=",4000-i, sep='')
print(url)
obs <- read_html(GET(url, config(ssl_verifypeer = FALSE)))
nodes <- obs %>%
html_nodes("p")
text <<- html_text(nodes)
#collecting abstracts
abstracts <- text[4]
#dates (this is gross code sorry!)
dates <- text[2]
}
for (i in 3395:3390)
{
url=paste("https://www.congress.gov/house-communication/117th-congress/executive-communication/",i,"?s=3&r=",4000-i, sep='')
print(url)
obs <- read_html(GET(url, config(ssl_verifypeer = FALSE)))
nodes <- obs %>%
html_nodes("p")
text <- html_text(nodes)
#collecting abstracts
abstracts <- text[4]
#dates (this is gross code sorry!)
dates <- text[2]
}
for(i in 19:1)
{
pres_url=paste("https://www.congress.gov/house-communication/117th-congress/presidential-message/",i,"?s=3&r=", 20-i, sep='')
print(pres_url)
obs <- read_html(GET(pres_url, config(ssl_verifypeer = FALSE)))
nodes <- obs %>%
html_nodes("p")
text <- html_text(nodes)
#collecting abstracts - need to collect for each url
abstracts <- nodes[3]
#dates
dates <- texts[2]
dates <- gsub(dates, pattern = "[a-z |A-Z ]", replace = "")
}
for(i in 19:1)
{
pres_url=paste("https://www.congress.gov/house-communication/117th-congress/presidential-message/",i,"?s=3&r=", 20-i, sep='')
print(pres_url)
obs <- read_html(GET(pres_url, config(ssl_verifypeer = FALSE)))
nodes <- obs %>%
html_nodes("p")
text <- html_text(nodes)
#collecting abstracts - need to collect for each url
abstracts <- nodes[3]
#dates
dates <- text[2]
dates <- gsub(dates, pattern = "[a-z |A-Z ]", replace = "")
}
dates
pres_url=paste("https://www.congress.gov/house-communication/117th-congress/presidential-message/",i,"?s=3&r=", 20-19, sep='')
obs <- read_html(GET(pres_url, config(ssl_verifypeer = FALSE)))
obs
nodes <- obs %>%
html_nodes("p")
nodes
text <- html_text(nodes)
text
abstracts <- nodes[3]
abstracts
dates <- text[2]
dates
dates <- gsub(dates, pattern = "[a-z |A-Z ]", replace = "")
dates
dates <- gsub(dates, pattern = "[a-z |A-Z | :]", replace = "")
dates
abstracts
exec <- data.frame()
colnames(exec) <- c("url", "date", "abstract", "committee")
exec <- data.frame()
colnames(exec) <- c("url", "date", "abstract", "committee")
exec <- data.frame(matrix(ncol=4,nrow=0, dimnames=list(NULL, c("url", "date", "abstract", "committee"))))
exec
text
exec <- data.frame(matrix(ncol=3,nrow=0, dimnames=list(NULL, c("url", "date", "abstract"))))
# will need to add 4th column for committee
#loop to collect EXECUTIVE COMMUNICATION
for (i in 3395:3390)
{
url <- paste("https://www.congress.gov/house-communication/117th-congress/executive-communication/",i,"?s=3&r=",4000-i, sep='')
print(url)
obs <- read_html(GET(url, config(ssl_verifypeer = FALSE)))
nodes <- obs %>%
html_nodes("p")
text <- html_text(nodes)
#collecting abstracts
abstract <- text[4]
#dates (this is gross code sorry!)
date <- text[2]
thisDat <- c(url, date, abstract)
exec <- rbind(exec, thisDat)
}
exec
View(exec)
str(exec)
exec <- data.frame(matrix(ncol=3,nrow=0))
exec
str(exec)
names(exec) <-  c("url", "date", "abstract")
exec
for (i in 3395:3390)
{
url <- paste("https://www.congress.gov/house-communication/117th-congress/executive-communication/",i,"?s=3&r=",4000-i, sep='')
print(url)
obs <- read_html(GET(url, config(ssl_verifypeer = FALSE)))
nodes <- obs %>%
html_nodes("p")
text <- html_text(nodes)
#collecting abstracts
abstract <- text[4]
#dates (this is gross code sorry!)
date <- text[2]
thisDat <- c(url, date, abstract)
exec <- rbind(exec, thisDat)
}
exec
dim(exec)
View(exec)
Open(exec)
exec[1]
exec[2]
exec[3]
exec <- data.frame(matrix(ncol=3,nrow=0))
names(exec) <-  c("url", "date", "abstract")
for (i in 3395:3390)
{
url <- paste("https://www.congress.gov/house-communication/117th-congress/executive-communication/",i,"?s=3&r=",4000-i, sep='')
print(url)
obs <- read_html(GET(url, config(ssl_verifypeer = FALSE)))
nodes <- obs %>%
html_nodes("p")
text <- html_text(nodes)
#collecting abstracts
abstract <- text[4]
#dates (this is gross code sorry!)
date <- text[2]
thisDat <- c(url, date, abstract)
exec <<- rbind(exec, thisDat)
}
View(exec)
exec[1]
exec[2]
exec[3]
exec[2]
rm(list = ls()) # clear global environ
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
# set working directory (change for each user)
wd <- "/Users/kellyfarley/Desktop/machine_learning/plsc468_psets"
#wd <- "/Users/numikatz/Documents/Senior_Year/Spring_22/PLSC_468/PLSC_468/plsc468_psets"
knitr::opts_knit$set(root.dir = wd)
# load libraries
library(RCurl)
library(stringr)
library(tm)
library(pryr)
library(corpus)
library(SnowballC)
library(textreadr)
library(httr)
library(rvest)
pres <- data.frame(matrix(ncol=3,nrow=0))
names(pres) <-  c("url", "date", "abstract")
pres
for(i in 19:11)
{
pres_url=paste("https://www.congress.gov/house-communication/117th-congress/presidential-message/",i,"?s=3&r=", 20-i, sep='')
print(pres_url)
obs <- read_html(GET(pres_url, config(ssl_verifypeer = FALSE)))
nodes <- obs %>%
html_nodes("p")
text <- html_text(nodes)
#collecting abstracts
abstract <- text[3]
date <- text[2]
#NEED COMMITTEE
thisDat <- c(url, date, abstract)
pres <<- rbind(pres, thisDat)
}
rm(list = ls()) # clear global environ
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
# set working directory (change for each user)
wd <- "/Users/kellyfarley/Desktop/machine_learning/plsc468_psets"
#wd <- "/Users/numikatz/Documents/Senior_Year/Spring_22/PLSC_468/PLSC_468/plsc468_psets"
knitr::opts_knit$set(root.dir = wd)
# load libraries
library(RCurl)
library(stringr)
library(tm)
library(pryr)
library(corpus)
library(SnowballC)
library(textreadr)
library(httr)
library(rvest)
pres <- data.frame(matrix(ncol=3,nrow=0))
names(pres) <-  c("url", "date", "abstract")
for(i in 19:11)
{
pres_url=paste("https://www.congress.gov/house-communication/117th-congress/presidential-message/",i,"?s=3&r=", 20-i, sep='')
print(pres_url)
obs <- read_html(GET(pres_url, config(ssl_verifypeer = FALSE)))
nodes <- obs %>%
html_nodes("p")
text <- html_text(nodes)
#collecting abstracts
abstract <- text[3]
date <- text[2]
#NEED COMMITTEE
thisDat <- c(url, date, abstract)
pres <- rbind(pres, thisDat)
}
rm(list = ls()) # clear global environ
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
# set working directory (change for each user)
wd <- "/Users/kellyfarley/Desktop/machine_learning/plsc468_psets"
#wd <- "/Users/numikatz/Documents/Senior_Year/Spring_22/PLSC_468/PLSC_468/plsc468_psets"
knitr::opts_knit$set(root.dir = wd)
# load libraries
library(RCurl)
library(stringr)
library(tm)
library(pryr)
library(corpus)
library(SnowballC)
library(textreadr)
library(httr)
library(rvest)
pres <- data.frame(matrix(ncol=3,nrow=0))
names(pres) <-  c("url", "date", "abstract")
for(i in 19:11)
{
pres_url=paste("https://www.congress.gov/house-communication/117th-congress/presidential-message/",i,"?s=3&r=", 20-i, sep='')
print(pres_url)
obs <- read_html(GET(pres_url, config(ssl_verifypeer = FALSE)))
nodes <- obs %>%
html_nodes("p")
text <- html_text(nodes)
#collecting abstracts
abstract <- text[3]
date <- text[2]
#NEED COMMITTEE
thisDat <- c(url, date, abstract)
pres <- rbind(pres, thisDat)
}
i<-19
pres_url=paste("https://www.congress.gov/house-communication/117th-congress/presidential-message/",i,"?s=3&r=", 20-i, sep='')
print(pres_url)
obs <- read_html(GET(pres_url, config(ssl_verifypeer = FALSE)))
nodes <- obs %>%
html_nodes("p")
text <- html_text(nodes)
#collecting abstracts
abstract <- text[3]
date <- text[2]
#NEED COMMITTEE
thisDat <- c(url, date, abstract)
pres <- rbind(pres, thisDat)
pres_url=paste("https://www.congress.gov/house-communication/117th-congress/presidential-message/",i,"?s=3&r=", 20-i, sep='')
print(pres_url)
obs <- read_html(GET(pres_url, config(ssl_verifypeer = FALSE)))
nodes <- obs %>%
html_nodes("p")
text <- html_text(nodes)
#collecting abstracts
abstract <- text[3]
date <- text[2]
pres_url=paste("https://www.congress.gov/house-communication/117th-congress/presidential-message/",i,"?s=3&r=", 20-i, sep='')
print(pres_url)
obs <- read_html(GET(pres_url, config(ssl_verifypeer = FALSE)))
nodes <- obs %>%
html_nodes("p")
text <- html_text(nodes)
#collecting abstracts
abstract <- text[3]
date <- text[2]
#NEED COMMITTEE
thisDat <- c(url, date, abstract)
pres <- rbind(pres, thisDat)
str(thisDat)
str(pres)
rbind(pres, thisDat)
pres_url=paste("https://www.congress.gov/house-communication/117th-congress/presidential-message/",i,"?s=3&r=", 20-i, sep='')
print(pres_url)
obs <- read_html(GET(pres_url, config(ssl_verifypeer = FALSE)))
nodes <- obs %>%
html_nodes("p")
text <- html_text(nodes)
#collecting abstracts
abstract <- text[3]
date <- text[2]
#NEED COMMITTEE
thisDat <- as.data.frame(c(url, date, abstract))
str(thisDat)
pres_url=paste("https://www.congress.gov/house-communication/117th-congress/presidential-message/",i,"?s=3&r=", 20-i, sep='')
print(pres_url)
obs <- read_html(GET(pres_url, config(ssl_verifypeer = FALSE)))
nodes <- obs %>%
html_nodes("p")
text <- html_text(nodes)
#collecting abstracts
abstract <- text[3]
date <- text[2]
#NEED COMMITTEE
thisDat <- data.frame(c(url, date, abstract))
thisDat <- data.frame(c(url, date, abstract))
pres <- rbind(pres, thisDat)
rm(list = ls()) # clear global environ
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
# set working directory (change for each user)
wd <- "/Users/kellyfarley/Desktop/machine_learning/plsc468_psets"
#wd <- "/Users/numikatz/Documents/Senior_Year/Spring_22/PLSC_468/PLSC_468/plsc468_psets"
knitr::opts_knit$set(root.dir = wd)
# load libraries
library(RCurl)
library(stringr)
library(tm)
library(pryr)
library(corpus)
library(SnowballC)
library(textreadr)
library(httr)
library(rvest)
#Goal: scrape abstract text, date, legislative committee(s) (if any)
exec <- data.frame(matrix(ncol=3,nrow=0))
names(exec) <-  c("url", "date", "abstract")
# will need to add 4th column for committee
#loop to collect EXECUTIVE COMMUNICATION
for (i in 3395:3390)
{
url <- paste("https://www.congress.gov/house-communication/117th-congress/executive-communication/",i,"?s=3&r=",4000-i, sep='')
print(url)
obs <- read_html(GET(url, config(ssl_verifypeer = FALSE)))
nodes <- obs %>%
html_nodes("p")
text <- html_text(nodes)
#collecting abstracts
abstract <- text[4]
#dates (this is gross code sorry!)
date <- text[2]
thisDat <- c(url, date, abstract)
exec <- rbind(exec, thisDat)
}
# need to clean up date and abstract t
#PRESIDENTIAL MESSAGE
pres <- data.frame(matrix(ncol=3,nrow=0))
names(pres) <-  c("url", "date", "abstract")
for(i in 19:11)
{
pres_url=paste("https://www.congress.gov/house-communication/117th-congress/presidential-message/",i,"?s=3&r=", 20-i, sep='')
print(pres_url)
obs <- read_html(GET(pres_url, config(ssl_verifypeer = FALSE)))
nodes <- obs %>%
html_nodes("p")
text <- html_text(nodes)
#collecting abstracts
abstract <- text[3]
date <- text[2]
#NEED COMMITTEE
thisDat <- data.frame(c(url, date, abstract))
pres <- rbind(pres, thisDat)
}
#cleaning dates code:
#   dates <- gsub(dates, pattern = "[a-z |A-Z | :]", replace = "")
#PETITION
pet <- data.frame(matrix(ncol=3,nrow=0))
names(pet) <-  c("url", "date", "abstract")
for(i in 96:95)
{
pet_url=paste("https://www.congress.gov/house-communication/117th-congress/petition/",i,"?s=3&r=", 97-i, sep='')
print(pet_url)
obs <- read_html(GET(pet_url, config(ssl_verifypeer = FALSE)))
nodes <- obs %>%
html_nodes("p")
text <- html_text(nodes)
#collecting abstracts
abstract <- text[3]
date <- text[2]
#NEED COMMITTEE
thisDat <- c(url, date, abstract)
pet <<- rbind(pet, thisDat)
}
#MEMORIAL
mem <- data.frame(matrix(ncol=3,nrow=0))
names(mem) <-  c("url", "date", "abstract")
for(i in 138:137)
{
mem_url=paste("https://www.congress.gov/house-communication/117th-congress/memorial/",i,"?s=3&r=", 139-i, sep='')
print(mem_url)
obs <- read_html(GET(mem_url, config(ssl_verifypeer = FALSE)))
nodes <- obs %>%
html_nodes("p")
text <- html_text(nodes)
#collecting abstracts
abstract <- text[3]
date <- text[2]
#NEED COMMITTEE
thisDat <- c(url, date, abstract)
mem <- rbind(mem, thisDat)
}
rm(list = ls()) # clear global environ
# set working directory (change for each user)
wd <- "/Users/kellyfarley/Desktop/machine_learning/plsc468_psets"
#wd <- "/Users/numikatz/Documents/Senior_Year/Spring_22/PLSC_468/PLSC_468/plsc468_psets"
# load libraries
library(RCurl)
library(stringr)
library(tm)
library(pryr)
library(corpus)
library(SnowballC)
library(textreadr)
library(httr)
library(rvest)
exec <- data.frame(matrix(ncol=3,nrow=0))
tibble(exec)
names(exec) <-  c("url", "date", "abstract")
# will need to add 4th column for committee
for (i in 3414:3413)
{
url <- paste("https://www.congress.gov/house-communication/117th-congress/executive-communication/",i,"?s=1&r=",3415-i, sep='')
print(url)
obs <- read_html(GET(url, config(ssl_verifypeer = FALSE)))
nodes <- obs %>%
html_nodes("p")
text <- html_text(nodes)
#collecting abstracts
abstract <- text[3]
#dates (this is gross code sorry!)
date <- text[2]
thisDat <- c(url, date, abstract)
exec <- rbind(exec, thisDat)
}
exec
View(exec)
3414:3413
View(exec)
exec[1]
rm(list = ls()) # clear global environ
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
# set working directory (change for each user)
wd <- "/Users/kellyfarley/Desktop/machine_learning/plsc468_psets"
#wd <- "/Users/numikatz/Documents/Senior_Year/Spring_22/PLSC_468/PLSC_468/plsc468_psets"
knitr::opts_knit$set(root.dir = wd)
# load libraries
library(RCurl)
library(stringr)
library(tm)
library(pryr)
library(corpus)
library(SnowballC)
library(textreadr)
library(httr)
library(rvest)
# chelsea test 11
exec <- data.frame(matrix(ncol=3,nrow=0))
#tibble(exec)
#names(exec) <-  c("url", "date", "abstract")
# will need to add 4th column for committee
for (i in 3414:3413)
{
url <- paste("https://www.congress.gov/house-communication/117th-congress/executive-communication/",i,"?s=1&r=",3415-i, sep='')
print(url)
obs <- read_html(GET(url, config(ssl_verifypeer = FALSE)))
nodes <- obs %>%
html_nodes("p")
text <- html_text(nodes)
#collecting abstracts
abstract <- text[3]
#dates (this is gross code sorry!)
date <- text[2]
thisDat <- c(url, date, abstract)
exec <- rbind(exec, thisDat)
names(exec) <- c("url", "date", "abstract")
}
View(exec)
