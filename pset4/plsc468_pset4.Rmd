---
title: "PLSC 468 Pset 4"
author: "Kelly Farley, Numi Katz, and Chelsea Wang"
date: "4/29/2022"
output:
  html_document:
    toc: yes
    toc_float: yes
    theme: united
  pdf_document:
    toc: yes
---

```{r setup, include=FALSE}
rm(list = ls()) # clear global environ

knitr::opts_chunk$set(echo = TRUE, cache = TRUE, warning = FALSE, message = FALSE)

# set working directory (change for each user)
wd <- "/Users/kellyfarley/Desktop/machine_learning/plsc468_psets"
# wd <- "/Users/numikatz/Documents/Senior_Year/Spring_22/PLSC_468/PLSC_468/plsc468_psets"
knitr::opts_knit$set(root.dir = wd)

# load libraries
library(tidyverse)
library(broom)
library(glmnet)
```

Setting the seed for future randomization:

```{r}
set.seed(1005)
```

Loading platforms from .rda file:

```{r}
load(file = "pset4/platforms.Rdata")
```

Goal: to use the lasso, ridge, and elastic net to classify the correct party (D or R) for 478 U.S. state party platforms

# 1a: Ridge Regression Model

**Using glmnet(), estimate a ridge regression model (alpha = 0) to predict party in a training set. In the model, include all 5056 words and a shrinkage parameter lambda = 5056/478.**

```{r}
# divide into test and training

N=nrow(tdoc)
s.vec=sample(1:2,replace=T,prob=c(1/2, 1/2),size=N)
  
# train with 1/2 of known
x.train <- tdoc[which(s.vec==1),]
y.train <- pty[which(s.vec==1)]
  
# test with other 1/2 of known
x.test <- tdoc[which(s.vec==2),]
y.test <- pty[which(s.vec==2)]
```

```{r}
# given parameter
lambda = 5056/478

# train
ridge_reg <- glmnet(x.train, y.train, alpha = 0, lambda = lambda)
```

**Using a separate testing set, assess how many platforms your ridge model correctly classified. What is the out-of-sample accuracy rate?**

```{r}
# test
test_1a <- ridge_reg$a0+x.test%*%ridge_reg$beta[,1]
tau=(min(test_1a[y.test==-1])+max(test_1a[y.test==1]))/2

y.pred <- as.numeric(test_1a>tau)
y.pred[y.pred == 0] <- -1

# calculate accuracy
sub.vector <- y.pred - y.test # 0's indicate correct classification
accuracy <- sum(sub.vector == 0) / length(sub.vector)
```

The out-of-sample accuracy rate is 80%.

# 1b: Lasso Regression Model

**Using glmnet(), estimate a lasso regression model (alpha = 1) to predict party in a training set. In the model, include all 5056 words and a shrinkage parameter lambda = 5056/478.**

```{r}
lasso_reg <- glmnet(x.train, y.train, alpha = 1, lambda = lambda)
```

**Using a separate testing set, assess how many platforms your lasso model correctly classified. What is the out-of-sample accuracy rate?**

```{r}
# test
test_1b <- lasso_reg$a0+x.test%*%lasso_reg$beta[,1]
tau=(min(test_1b[y.test==-1])+max(test_1b[y.test==1]))/2

y.pred <- as.numeric(test_1b>tau)
y.pred[y.pred == 0] <- -1

# calculate accuracy
sub.vector <- y.pred - y.test # 0's indicate correct classification
accuracy <- sum(sub.vector == 0) / length(sub.vector)
```

The out-of-sample accuracy is 54%.

# 1c: Elastic Net (TO DO)

**Combine the ridge and lasso models together using the elastic net with k-fold cross-validation using both glmnet() and cv.glmnet() functions. Set k=10 to do 10-fold cross-validation, search over alpha from 0-1 by increments of 0.1, search over lambda from 0.5-10.5 by increments of 0.5.**

```{r eval = F}
# initial tuning range
k=10
alpha=seq(from=0,to=1,by=0.1)
lambda=seq(from=0.5,to=10.5,by=0.5)

sumMSE=matrix(NA,length(alpha),length(lambda))

for(i in 1:length(alpha)){
  oo=cv.glmnet(nfolds=k,x=x.train, y=y.train, family=c("gaussian"),nlambda=length(lambda),
  	alpha=alpha[i],lambda=lambda)
  if(length(oo$cvm)==length(sumMSE[i,])){
  	sumMSE[i,]=oo$cvm
  }
}

# identifiying alpha and lamda that minimizes MSE
for(i in 1:length(alpha)){
  if(length(which(sumMSE[i,]==min(sumMSE)))>0){break}
}

alpha[i]
lambda[which(sumMSE[i,]==min(sumMSE))]

# run final optimized model
oo=glmnet(x=x.train, y=y.train, family=c("gaussian"),
  	alpha=alpha[i],lambda=lambda[which(sumMSE[i,]==min(sumMSE))])

# train
prd.train=predict(oo,x.train)
tau=(min(prd.train[y.train==1])+max(prd.train[y.train==0]))/2
table(y.train,as.numeric(prd.train>tau))

# test
prd.test=predict(oo,x.test)
table(y.test,as.numeric(prd.test>tau))
```

**Identify the alpha, lambda combination that maximizes prediction accuracy in training set.**

**Use chosen parameters to classify platforms in a testing set. How many platforms did your elastic net correctly classify? What is the out-of-sample accuracy rate?**