---
title: "PLSC 468 Final Project"
author: "Kelly Farley, Numi Katz, and Chelsea Wang"
date: "4/6/2022"
output:
  html_document:
    toc: yes
    toc_float: yes
    theme: united
  pdf_document:
    toc: yes
---

```{r setup, include=FALSE}
rm(list = ls()) # clear global environ

knitr::opts_chunk$set(echo = TRUE, cache = TRUE, warning = FALSE, message = FALSE)

# set working directory (change for each user)
wd <- "/Users/kellyfarley/Desktop/machine_learning/plsc468_psets"
#wd <- "/Users/numikatz/Documents/Senior_Year/Spring_22/PLSC_468/PLSC_468/plsc468_psets"
knitr::opts_knit$set(root.dir = wd)

# load libraries
library(e1071)
library(stringr)
library(tm)
library(tidyverse)
#library(reticulate)
#library(rjson)
#library(jsonlite)
#py_install("pandas")
```

# Load Data

Setting the seed for future randomization:

```{r}
set.seed(1005)
```

```{r}
# data source: https://github.com/smitp415/CSCI_544_Final_Project

raw <- read_csv(url("https://raw.githubusercontent.com/smitp415/CSCI_544_Final_Project/main/clean_data.csv")) #

dat <- raw
```

# Data Structure

```{r}
dim(dat)
```

We note 16 variables recorded for 3,303 SCOTUS cases. Only some of these variables are relevant for our analysis:

```{r}
dat <- dat %>%
  select(name, href, term, facts, majority_vote, minority_vote, decision_type, disposition, issue_area) %>%
  mutate(term = case_when(term == "1789-1850" ~ round(mean(c(1789, 1850)), 0),
                   term == "1850-1900" ~ round(mean(c(1850, 1900)), 0),
                   term == "1900-1940" ~ round(mean(c(1900, 1940)), 0),
                   term == "1940-1955" ~ round(mean(c(1940, 1955)), 0),
                   TRUE ~ as.numeric(term))) %>%
  mutate(term = as.numeric(term),
         decision_type = as.factor(decision_type),
         disposition = as.factor(disposition),
         issue_area = as.factor(issue_area))

load("final_project/mqData2020.Rda")

```

-name (character): The name of the case, e.g. "Roe v. Wade."
-href (character): The URL link to the case in the Oyez API, for ease of reference
-term (numeric): Since 1955, the term of the Supreme Court begins from October of the given year and extends til October of the following year. Previously, the term of the court has been classified into broader terms: 1789-1850, 1850-1900, 1900-1940, 1940-1955. For our analysis, we want to consider "term" as a continuous variable. Therefore, the ranged values will be replaced with the year in the middle of the range. While it would be preferred to have the actual year of the decision, we note that very few cases take place before 1955: only 59 of the over 3k cases.
-facts (character): This is the raw text of the case facts and needs to be cleaned for future analysis.
-majority_vote (numeric): The number of justices who agreed to the case's disposition
-minority_vote (numeric): The number of justices who did not agree to the case's disposition
-decision_type (factor): A phrase indicating the court's level of agreement on the case's outcome, e.g. "majority opinion," or "dismissal - moot"
-disposition (factor): A phrase indicating the court's judgement on the status of the case, e.g. "reversed" or "affirmed"
-issue_area (factor): A phrase indicating the topic of the case, e.g. "Civil Rights"

To ensure the dataset variables are as expected, we investigate the range of each variable.

```{r}
sum(duplicated(dat))
```

We note no duplicated entries in the dataset.

```{r}
range(dat$term)

ggplot(dat, aes(x=term)) +
  geom_histogram(fill="#8D9DD5", color="#E3EBFF") +
  theme_minimal() +
  xlab("Term") +
  ylab("Count") +
  scale_x_continuous(breaks=seq(1800, 2100, 50)) +
  scale_y_continuous(breaks=seq(0, 350, 100), limits=c(0, 250), expand=c(0,0)) +
  theme(
    axis.line = element_line(colour = "black"),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    panel.border = element_blank(),
    panel.background = element_blank(),
    text = element_text(family = "Palatino", size = 15),
    axis.title.y = element_text(face = "bold"),
    axis.title.x = element_text(face = "bold"),
  )

sum(dat$term < 1950)

dat <- dat %>%
  filter(term >= 1950)
```

The terms from the dataset range from 1820 to 2020. We note the vast majority of cases in the dataset are from after 1950: only 59 out of the over 3k cases are from earlier. Therefore, we decide to cutoff the dataset at cases in 1950 or later, with the most recent cases being from the term ending in October of 2021.

```{r}
votes <- dat %>%
  select(majority_vote, minority_vote)

votes <- gather(votes, condition, measurement)

ggplot(votes, aes(x=measurement, fill=condition)) +
  geom_histogram() +
  theme_minimal() +
  xlab("Justices") +
  ylab("Count") +
  scale_x_continuous(breaks=seq(0, 9, 1)) +
  theme(
    axis.line = element_line(colour = "black"),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    panel.border = element_blank(),
    panel.background = element_blank(),
    text = element_text(family = "Palatino", size = 15),
    axis.title.y = element_text(face = "bold"),
    axis.title.x = element_text(face = "bold"),
  )
```

We note that majority vote opinions generally occur when 5-9 justices agree on the opinion, leaving a minority of 0-4 justices dissenting. We also note that the most common condition is consensus, when 9 of the justices are on the majority vote and 0 justices are on the minority vote. 

```{r}
table(dat$majority_vote)
```

```{r}
ggplot(dat, aes(x=decision_type)) +
  geom_bar(fill="#8D9DD5", color="#E3EBFF") +
  theme_minimal() +
  xlab("Decision Type") +
  scale_x_discrete(guide = guide_axis(n.dodge=3)) +
  ylab("Count") +
  theme(
    axis.line = element_line(colour = "black"),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    panel.border = element_blank(),
    panel.background = element_blank(),
    text = element_text(family = "Palatino", size = 10),
    axis.title.y = element_text(face = "bold"),
    axis.title.x = element_text(face = "bold"),
  )
```
We note the vast majority of the Court's decisions are majority opinions, where more than half of the Court agrees on the decision and the reasoning. A plurality opinion has the greatest number of votes but not necessarily a majority and is not binding. These opinions typically have 1 justice as the author. In contrast, per curiam opinions do not identify an author and are opinions of the Court.

```{r}
ggplot(dat, aes(x=disposition)) +
  geom_bar(fill="#8D9DD5", color="#E3EBFF") +
  theme_minimal() +
  xlab("Disposition") +
  scale_x_discrete(guide = guide_axis(n.dodge=3)) +
  ylab("Count") +
  theme(
    axis.line = element_line(colour = "black"),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    panel.border = element_blank(),
    panel.background = element_blank(),
    text = element_text(family = "Palatino", size = 10),
    axis.title.y = element_text(face = "bold"),
    axis.title.x = element_text(face = "bold"),
  )
```

We note a variety of decision types: interestingly, the court affirms a decision about as often as it reverses/remands a decision.

```{r}
ggplot(dat, aes(x=issue_area)) +
  geom_bar(fill="#8D9DD5", color="#E3EBFF") +
  theme_minimal() +
  xlab("Issue Area") +
  scale_x_discrete(guide = guide_axis(n.dodge=3)) +
  ylab("Count") +
  theme(
    axis.line = element_line(colour = "black"),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    panel.border = element_blank(),
    panel.background = element_blank(),
    text = element_text(family = "Palatino", size = 10),
    axis.title.y = element_text(face = "bold"),
    axis.title.x = element_text(face = "bold"),
  )
```

We note a variety of issue areas, particularly Civil Rights, Criminal Procedure, and Economic Activity.

https://mqscores.lsa.umich.edu/measures.php dataset of justice leanings 1937-2020 by justice with the year the justice serves...slight issue bc a few years have over 9 justices (times of switchover), but our model simply will just not deal with this... lol

# Most Frequent Words

Copy from Pset 1
Most frequent words across corpus, most frequent words across guilty versus not guilty, words with highest correlation

## Analysis

*What can this tell us about differences btwn guilty and not guilty verdicts?*

## Future Suggestions

# Verdict Prediction

Copy from Pset 2
Build test, training, prediction
Choose stopword, non-stopword, fighting words, Bayesian method

First, we break up our document term matrix into two separate dtm's: stop words (stop.dtm, for use in 1a) and non-stop words (non.dtm, for use in 1b). We use the stop words from the stopword package.

```{r}
# using stop words from stopword() package
stops <- stopwords(kind = "en")

# note apostrophes are not removed in stops, but are in our texts
stops <- c(gsub(stops, pattern="[']", replace=''))

# make corpus
texts=VCorpus(VectorSource(dat$facts))

# make dtm
dtm = as.matrix(DocumentTermMatrix(texts))

# remove non stop words

non.stops=array(TRUE,ncol(dtm))

stops=sort(stops)

col.names=colnames(dtm)
for(j in 1:length(stops)){
	ik=which(stops[j]==col.names)
	if(length(ik)>0){
		non.stops[ik]=F
	}
}

non.dtm  = dtm[,non.stops] # non-stop words
stop.dtm = dtm[,!non.stops] # stop words
```

Now, we work with the stop words dtm to make training (50% of known papers), testing (other 50% of known papers), and prediction (all disputed papers) sets. Note that we used our discretion on this training/testing proportion and have decided to split the known papers exactly in half due to overfitting and validation tradeoffs. We make this into the function splitSets() that can be used elsewhere in the pset and also, due to function scope, ensure that all variables needed later on (x.train, y.train, x.test, y.test, x.pred) are stored as global variables using the operator <<-.

```{r eval=F}
# function to split into testing, training, prediction sets
splitSets <- function(dtm){
  # define training, testing, and prediction sets
  
  # randomly assign known papers to training (50%) and testing (50%)
  N=nrow(dtm)
  s.vec=sample(1:2,replace=T,prob=c(1/2, 1/2),size=N)
  
  # train with 1/2 of known
  x.train <<- dtm[which(s.vec==1),]
  y.train <<- dtm$classes[which(s.vec==1)]
  
  # test with other 1/2 of known
  x.test <<- dtm[which(s.vec==2),]
  y.test <<- knownpapers$classes[which(s.vec==2)]
}

splitSets(stop.dtm)
```

## Analysis

*Are we able to predict guilty vs not guilty verdicts? What's the best method for prediction?*

## Future Suggestions