train.prediction=as.numeric(Z.train>mean(Z.train))
# testing set
z.test=x.test
for(j in 1:length(w.train)){
z.test[,j]=w.train[j]*x.test[,j]
}
Z.test=rowSums(z.test)
test.prediction=as.numeric(Z.test>mean(Z.test))
# predicting disputed papers
z.pred=x.pred
for(j in 1:length(w.train)){
z.pred[,j]=w.train[j]*x.pred[,j]
}
Z.pred=rowSums(z.pred)
pred.prediction=as.numeric(Z.pred>mean(Z.pred))
# we want test.prediction and pred.prediction for future analysis
predictions <- vector(mode = "list", length = 2)
predictions[[1]] <- unlist(test.prediction)
predictions[[2]] <- unlist(pred.prediction)
return(predictions)
}
testTrim <- function(method) {
# empty dataframe to store predictions
cutoffPredictions <- data.frame(matrix(ncol = 3, nrow = length(cutoffValues)))
names(cutoffPredictions) <- c("cutoff", "test.prediction", "pred.prediction")
# try different cutoffs
for(i in 1:length(cutoffValues)){
thisPrediction <- ttp(cutoffValues[[i]], method)
# note have to convert data type from vector to string to store in data frame
cutoffPredictions[i, ] <- c(cutoffValues[[i]], paste(thisPrediction[[1]], collapse=" "), paste(thisPrediction[[2]], collapse=" "))
}
# store predictions in global variable
cutoffPredictions <<- cutoffPredictions
}
testTrim("normal")
# function to calculate accuracy, precision, recall
apr <- function(cutoff, test.prediction){
add.vector <- test.prediction + y.train
# 2's indicate truly H, 0's indicate truly M
true_hamilton <- sum(add.vector==2)
true_madison <- sum(add.vector==0)
sub.vector <- y.train - test.prediction
# +1 indicates classified as H when M, -1 indicates classified as M when H
false_hamilton <- sum(add.vector==1)
false_madison <- sum(add.vector==-1)
# overall accuracy
accuracy <- (true_hamilton + true_madison) / (true_hamilton + true_madison + false_hamilton + false_madison)
# precision for madison
precision_madison <- true_madison / (true_madison + false_madison)
# precision for hamilton
precision_hamilton <- true_hamilton / (true_hamilton + false_hamilton)
# recall for madison
recall_madison <- true_madison / (true_madison + false_hamilton)
# recall for hamilton
recall_hamilton <- true_hamilton / (true_hamilton + false_madison)
# compiled results
results <- c(accuracy, precision_madison, precision_hamilton, recall_madison, recall_hamilton)
return(results)
}
runapr <- function(){
# empty list to store results
results <- vector(mode = "list", length = length(cutoffValues))
# run apr on each of the tests for the cutoff values
for(i in 1:length(cutoffValues)){
test.prediction <<- as.numeric(strsplit(cutoffPredictions$test.prediction[i], " ")[[1]])
results[[i]] <- apr(cutoffValues[[i]], test.prediction)
}
resultsDf <- as.data.frame(rbind(results[[1]], results[[2]], results[[3]], results[[4]])) # NOTE: will need to modified if number of cutoffs tested is modified
colnames(resultsDf) <- c("accuracy", "precision_madison", "precision_hamilton", "recall_madison", "recall_hamilton")
resultsDf <<- round(resultsDf, 2)
}
runapr()
print(resultsDf)
w.train
w.train <- dictionW(x=x.train,y=y.train)
w.train
sort(w.train)
temp1 <- w.train
temp2 <- w.train[which(abs(w.train)<cutoff)]
temp2 <- w.train[which(abs(w.train)<0.1)]
temp2
w.train[which(abs(w.train)<0.2)]
w.train[which(abs(w.train)<0.3)]
w.train[which(abs(w.train)<0.4)]
rm(list = ls()) # clear global environ
knitr::opts_chunk$set(echo = TRUE, cache = TRUE, warnings = FALSE, message = FALSE)
# set working directory (change for each user)
wd <- "/Users/kellyfarley/Desktop/machine_learning/plsc468_psets"
#wd <- "/Users/numikatz/Documents/Senior_Year/Spring_22/PLSC_468/PLSC_468/plsc468_psets"
knitr::opts_knit$set(root.dir = wd)
# load libraries
library(stringr)
library(tm)
library(tidyverse)
set.seed(1005)
load(file = "pset2/federalists.Rdata")
# using stop words from stopword() package
stops <- stopwords(kind = "en")
# note apostrophes are not removed in stops, but are in our texts
stops <- c(gsub(stops, pattern="[']", replace=''))
# make corpus
texts=VCorpus(VectorSource(papers[,1]))
# make dtm
dtm = as.matrix(DocumentTermMatrix(texts))
# remove non stop words
non.stops=array(TRUE,ncol(dtm))
stops=sort(stops)
col.names=colnames(dtm)
for(j in 1:length(stops)){
ik=which(stops[j]==col.names)
if(length(ik)>0){
non.stops[ik]=F
}
}
non.dtm  = dtm[,non.stops] # non-stop words
stop.dtm = dtm[,!non.stops] # stop words
# get row IDs for known and disputed papers
papers <- as.data.frame(papers)
knownpapers_ids <- which(papers$classes == c("hamilton", "madison"), arr.ind=TRUE)
disputedpapers_ids <- which(papers$classes == "disputed", arr.ind=TRUE)
# split papers into known and disputed
knownpapers <- papers[knownpapers_ids,]
disputedpapers <- papers[disputedpapers_ids,]
# recode known papers into 0 (madison) and 1 (hamilton)
knownpapers <- knownpapers %>%
mutate(classes = case_when(classes=="hamilton" ~ 1,
classes=="madison" ~ 0))
# function to split into testing, training, prediction sets
splitSets <- function(dtm){
# split dtm into known and disputed
dtm.known <- dtm[knownpapers_ids,]
dtm.disputed <- dtm[disputedpapers_ids,]
# define training, testing, and prediction sets
# randomly assign known papers to training (50%) and testing (50%)
N=nrow(dtm.known)
s.vec=sample(1:2,replace=T,prob=c(1/2, 1/2),size=N)
# train with 1/2 of known
x.train <<- dtm.known[which(s.vec==1),]
y.train <<- knownpapers$classes[which(s.vec==1)]
# test with other 1/2 of known
x.test <<- dtm.known[which(s.vec==2),]
y.test <<- knownpapers$classes[which(s.vec==2)]
# predicted disputed
x.pred <<- dtm.disputed
#y.pred is unknown
}
splitSets(stop.dtm)
# function to weight words
dictionW=function(x,y){
sum.1=colSums(x[which(y==1),])
sum.0=colSums(x[which(y==0),])
rate.1=sum.1/(sum.0+sum.1)
rate.0=sum.0/(sum.0+sum.1)
var.1=rate.1*(1-rate.1)
var.0=rate.0*(1-rate.0)
# degenerate words get 0 weight
rate.1[which(sum.1==0)]=0
rate.0[which(sum.0==0)]=0
var.1[which(sum.1==0)]=1
var.0[which(sum.0==0)]=1
w=(rate.1-rate.0)/(var.1+var.0)
return(w)
}
# trim values to test
cutoffValues <- c(0.1, 0.2, 0.3, 0.5)
ttp <- function(cutoff, method){
# produce a predictor score in training set
# for 1a, 1b
if(method=="normal"){
w.train <- dictionW(x=x.train,y=y.train)
}
# for dirch weights in 1c
if(method=="dirch"){
w.train <- FightinW(x=x.train,y=y.train)
}
# test different cutoffs for trimming (TODO: IS THIS OK?)
w.train <- w.train[which(abs(w.train)<cutoff)]
z.train=x.train
for(j in 1:length(w.train)){
z.train[,j]=w.train[j]*x.train[,j]
}
Z.train=rowSums(z.train)
train.prediction=as.numeric(Z.train>mean(Z.train))
# testing set
z.test=x.test
for(j in 1:length(w.train)){
z.test[,j]=w.train[j]*x.test[,j]
}
Z.test=rowSums(z.test)
test.prediction=as.numeric(Z.test>mean(Z.test))
# predicting disputed papers
z.pred=x.pred
for(j in 1:length(w.train)){
z.pred[,j]=w.train[j]*x.pred[,j]
}
Z.pred=rowSums(z.pred)
pred.prediction=as.numeric(Z.pred>mean(Z.pred))
# we want test.prediction and pred.prediction for future analysis
predictions <- vector(mode = "list", length = 2)
predictions[[1]] <- unlist(test.prediction)
predictions[[2]] <- unlist(pred.prediction)
return(predictions)
}
testTrim <- function(method) {
# empty dataframe to store predictions
cutoffPredictions <- data.frame(matrix(ncol = 3, nrow = length(cutoffValues)))
names(cutoffPredictions) <- c("cutoff", "test.prediction", "pred.prediction")
# try different cutoffs
for(i in 1:length(cutoffValues)){
thisPrediction <- ttp(cutoffValues[[i]], method)
# note have to convert data type from vector to string to store in data frame
cutoffPredictions[i, ] <- c(cutoffValues[[i]], paste(thisPrediction[[1]], collapse=" "), paste(thisPrediction[[2]], collapse=" "))
}
# store predictions in global variable
cutoffPredictions <<- cutoffPredictions
}
testTrim("normal")
# function to calculate accuracy, precision, recall
apr <- function(cutoff, test.prediction){
add.vector <- test.prediction + y.train
# 2's indicate truly H, 0's indicate truly M
true_hamilton <- sum(add.vector==2)
true_madison <- sum(add.vector==0)
sub.vector <- y.train - test.prediction
# +1 indicates classified as H when M, -1 indicates classified as M when H
false_hamilton <- sum(add.vector==1)
false_madison <- sum(add.vector==-1)
# overall accuracy
accuracy <- (true_hamilton + true_madison) / (true_hamilton + true_madison + false_hamilton + false_madison)
# precision for madison
precision_madison <- true_madison / (true_madison + false_madison)
# precision for hamilton
precision_hamilton <- true_hamilton / (true_hamilton + false_hamilton)
# recall for madison
recall_madison <- true_madison / (true_madison + false_hamilton)
# recall for hamilton
recall_hamilton <- true_hamilton / (true_hamilton + false_madison)
# compiled results
results <- c(accuracy, precision_madison, precision_hamilton, recall_madison, recall_hamilton)
return(results)
}
runapr <- function(){
# empty list to store results
results <- vector(mode = "list", length = length(cutoffValues))
# run apr on each of the tests for the cutoff values
for(i in 1:length(cutoffValues)){
test.prediction <<- as.numeric(strsplit(cutoffPredictions$test.prediction[i], " ")[[1]])
results[[i]] <- apr(cutoffValues[[i]], test.prediction)
}
resultsDf <- as.data.frame(rbind(results[[1]], results[[2]], results[[3]], results[[4]])) # NOTE: will need to modified if number of cutoffs tested is modified
colnames(resultsDf) <- c("accuracy", "precision_madison", "precision_hamilton", "recall_madison", "recall_hamilton")
resultsDf <<- round(resultsDf, 2)
}
runapr()
print(resultsDf)
stop.prediction <- as.numeric(strsplit(cutoffPredictions$pred.prediction[1], " ")[[1]])
stop_results <- as.numeric(resultsDf[1, ])
splitSets(stop.dtm)
testTrim("normal")
runapr()
print(resultsDf)
nonstop.prediction <- as.numeric(strsplit(cutoffPredictions$pred.prediction[1], " ")[[1]])
nonstop_results <- as.numeric(resultsDf[1, ])
classMat <- rbind(stop.prediction, nonstop.prediction)
classMat <- as.data.frame(classMat)
colnames(classMat) <- disputedpapers_ids
classMat
resultsMat <- rbind(stop_results, nonstop_results)
colnames(resultsMat) <- c("overall accuracy", "precision_madison", "precision_hamilton", "recall_madison", "recall_hamilton")
resultsMat <- as.data.frame(resultsMat)
resultsMat <- round(resultsMat, 2)
resultsMat
testTrim("dirch")
FightinW=function(x,y){
# from FightinW in class5
sum.1=colSums(x[which(y==1),])
sum.0=colSums(x[which(y==0),])
# from FightinW in class5
rate.1=sum.1/sum(sum.1)
rate.0=sum.0/sum(sum.0)
# from dictionW() code
var.1=rate.1*(1-rate.1)
var.0=rate.0*(1-rate.0)
#dirichlet weights (flattish weights)
a.1=sum.1+1
a.0=sum.0+1
dirch.1=(sum.1+a.1)/(sum(sum.1)+sum(a.1))
dirch.0=(sum.0+a.0)/(sum(sum.0)+sum(a.0))
# from dictionW() code
w=(dirch.1-dirch.0)/(var.1+var.0)
return(w)
}
testTrim("dirch")
runapr()
print(resultsDf)
View(resultsDf)
cutoffValues
rm(list = ls()) # clear global environ
knitr::opts_chunk$set(echo = TRUE, cache = TRUE, warnings = FALSE, message = FALSE)
# set working directory (change for each user)
wd <- "/Users/kellyfarley/Desktop/machine_learning/plsc468_psets"
#wd <- "/Users/numikatz/Documents/Senior_Year/Spring_22/PLSC_468/PLSC_468/plsc468_psets"
knitr::opts_knit$set(root.dir = wd)
# load libraries
library(stringr)
library(tm)
library(tidyverse)
set.seed(1005)
load(file = "pset2/federalists.Rdata")
# using stop words from stopword() package
stops <- stopwords(kind = "en")
# note apostrophes are not removed in stops, but are in our texts
stops <- c(gsub(stops, pattern="[']", replace=''))
# make corpus
texts=VCorpus(VectorSource(papers[,1]))
# make dtm
dtm = as.matrix(DocumentTermMatrix(texts))
# remove non stop words
non.stops=array(TRUE,ncol(dtm))
stops=sort(stops)
col.names=colnames(dtm)
for(j in 1:length(stops)){
ik=which(stops[j]==col.names)
if(length(ik)>0){
non.stops[ik]=F
}
}
non.dtm  = dtm[,non.stops] # non-stop words
stop.dtm = dtm[,!non.stops] # stop words
# get row IDs for known and disputed papers
papers <- as.data.frame(papers)
knownpapers_ids <- which(papers$classes == c("hamilton", "madison"), arr.ind=TRUE)
disputedpapers_ids <- which(papers$classes == "disputed", arr.ind=TRUE)
# split papers into known and disputed
knownpapers <- papers[knownpapers_ids,]
disputedpapers <- papers[disputedpapers_ids,]
# recode known papers into 0 (madison) and 1 (hamilton)
knownpapers <- knownpapers %>%
mutate(classes = case_when(classes=="hamilton" ~ 1,
classes=="madison" ~ 0))
# function to split into testing, training, prediction sets
splitSets <- function(dtm){
# split dtm into known and disputed
dtm.known <- dtm[knownpapers_ids,]
dtm.disputed <- dtm[disputedpapers_ids,]
# define training, testing, and prediction sets
# randomly assign known papers to training (50%) and testing (50%)
N=nrow(dtm.known)
s.vec=sample(1:2,replace=T,prob=c(1/2, 1/2),size=N)
# train with 1/2 of known
x.train <<- dtm.known[which(s.vec==1),]
y.train <<- knownpapers$classes[which(s.vec==1)]
# test with other 1/2 of known
x.test <<- dtm.known[which(s.vec==2),]
y.test <<- knownpapers$classes[which(s.vec==2)]
# predicted disputed
x.pred <<- dtm.disputed
#y.pred is unknown
}
splitSets(stop.dtm)
# function to weight words
dictionW=function(x,y){
sum.1=colSums(x[which(y==1),])
sum.0=colSums(x[which(y==0),])
rate.1=sum.1/(sum.0+sum.1)
rate.0=sum.0/(sum.0+sum.1)
var.1=rate.1*(1-rate.1)
var.0=rate.0*(1-rate.0)
# degenerate words get 0 weight
rate.1[which(sum.1==0)]=0
rate.0[which(sum.0==0)]=0
var.1[which(sum.1==0)]=1
var.0[which(sum.0==0)]=1
w=(rate.1-rate.0)/(var.1+var.0)
return(w)
}
# trim values to test
cutoffValues <- c(0.1, 0.2, 0.3, 0.5)
ttp <- function(cutoff, method){
# produce a predictor score in training set
# for 1a, 1b
if(method=="normal"){
w.train <- dictionW(x=x.train,y=y.train)
}
# for dirch weights in 1c
if(method=="dirch"){
w.train <- FightinW(x=x.train,y=y.train)
}
# test different cutoffs for trimming (TODO: IS THIS OK?)
w.train <- w.train[which(abs(w.train)<cutoff)]
z.train=x.train
for(j in 1:length(w.train)){
z.train[,j]=w.train[j]*x.train[,j]
}
Z.train=rowSums(z.train)
train.prediction=as.numeric(Z.train>mean(Z.train))
# testing set
z.test=x.test
for(j in 1:length(w.train)){
z.test[,j]=w.train[j]*x.test[,j]
}
Z.test=rowSums(z.test)
test.prediction=as.numeric(Z.test>mean(Z.test))
# predicting disputed papers
z.pred=x.pred
for(j in 1:length(w.train)){
z.pred[,j]=w.train[j]*x.pred[,j]
}
Z.pred=rowSums(z.pred)
pred.prediction=as.numeric(Z.pred>mean(Z.pred))
# we want test.prediction and pred.prediction for future analysis
predictions <- vector(mode = "list", length = 2)
predictions[[1]] <- unlist(test.prediction)
predictions[[2]] <- unlist(pred.prediction)
return(predictions)
}
testTrim <- function(method) {
# empty dataframe to store predictions
cutoffPredictions <- data.frame(matrix(ncol = 3, nrow = length(cutoffValues)))
names(cutoffPredictions) <- c("cutoff", "test.prediction", "pred.prediction")
# try different cutoffs
for(i in 1:length(cutoffValues)){
thisPrediction <- ttp(cutoffValues[[i]], method)
# note have to convert data type from vector to string to store in data frame
cutoffPredictions[i, ] <- c(cutoffValues[[i]], paste(thisPrediction[[1]], collapse=" "), paste(thisPrediction[[2]], collapse=" "))
}
# store predictions in global variable
cutoffPredictions <<- cutoffPredictions
}
testTrim("normal")
# function to calculate accuracy, precision, recall
apr <- function(cutoff, test.prediction){
add.vector <- test.prediction + y.train
# 2's indicate truly H, 0's indicate truly M
true_hamilton <- sum(add.vector==2)
true_madison <- sum(add.vector==0)
sub.vector <- y.train - test.prediction
# +1 indicates classified as H when M, -1 indicates classified as M when H
false_hamilton <- sum(add.vector==1)
false_madison <- sum(add.vector==-1)
# overall accuracy
accuracy <- (true_hamilton + true_madison) / (true_hamilton + true_madison + false_hamilton + false_madison)
# precision for madison
precision_madison <- true_madison / (true_madison + false_madison)
# precision for hamilton
precision_hamilton <- true_hamilton / (true_hamilton + false_hamilton)
# recall for madison
recall_madison <- true_madison / (true_madison + false_hamilton)
# recall for hamilton
recall_hamilton <- true_hamilton / (true_hamilton + false_madison)
# compiled results
results <- c(accuracy, precision_madison, precision_hamilton, recall_madison, recall_hamilton)
return(results)
}
runapr <- function(){
# empty list to store results
results <- vector(mode = "list", length = length(cutoffValues))
# run apr on each of the tests for the cutoff values
for(i in 1:length(cutoffValues)){
test.prediction <<- as.numeric(strsplit(cutoffPredictions$test.prediction[i], " ")[[1]])
results[[i]] <- apr(cutoffValues[[i]], test.prediction)
}
resultsDf <- as.data.frame(rbind(results[[1]], results[[2]], results[[3]], results[[4]])) # NOTE: will need to modified if number of cutoffs tested is modified
colnames(resultsDf) <- c("accuracy", "precision_madison", "precision_hamilton", "recall_madison", "recall_hamilton")
resultsDf <<- round(resultsDf, 2)
}
runapr()
print(resultsDf)
stop.prediction <- as.numeric(strsplit(cutoffPredictions$pred.prediction[1], " ")[[1]])
stop_results <- as.numeric(resultsDf[1, ])
splitSets(stop.dtm)
testTrim("normal")
runapr()
print(resultsDf)
nonstop.prediction <- as.numeric(strsplit(cutoffPredictions$pred.prediction[1], " ")[[1]])
nonstop_results <- as.numeric(resultsDf[1, ])
# fighting words weight function
FightinW=function(x,y){
# from FightinW in class5
sum.1=colSums(x[which(y==1),])
sum.0=colSums(x[which(y==0),])
# from FightinW in class5
rate.1=sum.1/sum(sum.1)
rate.0=sum.0/sum(sum.0)
# from dictionW() code
var.1=rate.1*(1-rate.1)
var.0=rate.0*(1-rate.0)
#dirichlet weights (flattish weights)
a.1=sum.1+1
a.0=sum.0+1
dirch.1=(sum.1+a.1)/(sum(sum.1)+sum(a.1))
dirch.0=(sum.0+a.0)/(sum(sum.0)+sum(a.0))
# from dictionW() code
w=(dirch.1-dirch.0)/(var.1+var.0)
return(w)
}
# same steps as before, changing weighting method to "dirch"
splitSets(non.dtm)
testTrim("dirch")
runapr()
print(resultsDf)
fightingW.prediction <- as.numeric(strsplit(cutoffPredictions$pred.prediction[1], " ")[[1]])
fightingW_results <- as.numeric(resultsDf[1, ])
classMat <- rbind(stop.prediction, nonstop.prediction, fightingW.prediction)
classMat <- as.data.frame(classMat)
colnames(classMat) <- disputedpapers_ids
classMat
resultsMat <- rbind(stop_results, nonstop_results, fightingW_results)
colnames(resultsMat) <- c("overall accuracy", "precision_madison", "precision_hamilton", "recall_madison", "recall_hamilton")
resultsMat <- as.data.frame(resultsMat)
resultsMat <- round(resultsMat, 2)
resultsMat
